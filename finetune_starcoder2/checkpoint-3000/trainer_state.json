{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.2,
  "eval_steps": 500,
  "global_step": 3000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.004,
      "grad_norm": 0.3426077663898468,
      "learning_rate": 2e-05,
      "loss": 2.9314,
      "step": 10
    },
    {
      "epoch": 0.008,
      "grad_norm": 0.5724144577980042,
      "learning_rate": 4e-05,
      "loss": 2.8247,
      "step": 20
    },
    {
      "epoch": 0.012,
      "grad_norm": 0.7688854336738586,
      "learning_rate": 6e-05,
      "loss": 2.5122,
      "step": 30
    },
    {
      "epoch": 0.016,
      "grad_norm": 0.8625675439834595,
      "learning_rate": 8e-05,
      "loss": 2.7368,
      "step": 40
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.1354831457138062,
      "learning_rate": 0.0001,
      "loss": 2.3019,
      "step": 50
    },
    {
      "epoch": 0.024,
      "grad_norm": 3.378488540649414,
      "learning_rate": 0.00012,
      "loss": 2.3206,
      "step": 60
    },
    {
      "epoch": 0.028,
      "grad_norm": 1.3570775985717773,
      "learning_rate": 0.00014,
      "loss": 2.0744,
      "step": 70
    },
    {
      "epoch": 0.032,
      "grad_norm": NaN,
      "learning_rate": 0.00015800000000000002,
      "loss": 1.8436,
      "step": 80
    },
    {
      "epoch": 0.036,
      "grad_norm": 4.027080535888672,
      "learning_rate": 0.00017800000000000002,
      "loss": 2.3957,
      "step": 90
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.2452301979064941,
      "learning_rate": 0.00019800000000000002,
      "loss": 2.1942,
      "step": 100
    },
    {
      "epoch": 0.044,
      "grad_norm": 4.084047317504883,
      "learning_rate": 0.0001999983352025441,
      "loss": 1.8502,
      "step": 110
    },
    {
      "epoch": 0.048,
      "grad_norm": 2.900085210800171,
      "learning_rate": 0.00019999258041830607,
      "loss": 1.8054,
      "step": 120
    },
    {
      "epoch": 0.052,
      "grad_norm": 3.3914549350738525,
      "learning_rate": 0.0001999827153307312,
      "loss": 1.9059,
      "step": 130
    },
    {
      "epoch": 0.056,
      "grad_norm": 2.0497732162475586,
      "learning_rate": 0.00019996874034533462,
      "loss": 1.496,
      "step": 140
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.8106114864349365,
      "learning_rate": 0.00019995065603657316,
      "loss": 2.0725,
      "step": 150
    },
    {
      "epoch": 0.064,
      "grad_norm": 1.7514961957931519,
      "learning_rate": 0.000199928463147822,
      "loss": 1.9731,
      "step": 160
    },
    {
      "epoch": 0.068,
      "grad_norm": 3.570523262023926,
      "learning_rate": 0.00019990216259134386,
      "loss": 1.6582,
      "step": 170
    },
    {
      "epoch": 0.072,
      "grad_norm": 1.4778298139572144,
      "learning_rate": 0.0001998717554482516,
      "loss": 2.0631,
      "step": 180
    },
    {
      "epoch": 0.076,
      "grad_norm": 4.078042507171631,
      "learning_rate": 0.00019983724296846375,
      "loss": 1.6277,
      "step": 190
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.9864320755004883,
      "learning_rate": 0.00019979862657065324,
      "loss": 1.8355,
      "step": 200
    },
    {
      "epoch": 0.084,
      "grad_norm": 2.8769729137420654,
      "learning_rate": 0.00019975590784218888,
      "loss": 1.9431,
      "step": 210
    },
    {
      "epoch": 0.088,
      "grad_norm": 4.924728870391846,
      "learning_rate": 0.00019970908853907026,
      "loss": 1.7316,
      "step": 220
    },
    {
      "epoch": 0.092,
      "grad_norm": 1.9807220697402954,
      "learning_rate": 0.00019965817058585563,
      "loss": 1.7061,
      "step": 230
    },
    {
      "epoch": 0.096,
      "grad_norm": 3.0840351581573486,
      "learning_rate": 0.00019960315607558255,
      "loss": 1.7857,
      "step": 240
    },
    {
      "epoch": 0.1,
      "grad_norm": 3.5300915241241455,
      "learning_rate": 0.0001995440472696821,
      "loss": 1.6178,
      "step": 250
    },
    {
      "epoch": 0.104,
      "grad_norm": 1.3585745096206665,
      "learning_rate": 0.00019948084659788574,
      "loss": 1.4387,
      "step": 260
    },
    {
      "epoch": 0.108,
      "grad_norm": 6.052093029022217,
      "learning_rate": 0.00019941355665812558,
      "loss": 1.8342,
      "step": 270
    },
    {
      "epoch": 0.112,
      "grad_norm": 1.362105131149292,
      "learning_rate": 0.00019934218021642748,
      "loss": 1.9202,
      "step": 280
    },
    {
      "epoch": 0.116,
      "grad_norm": 3.1927781105041504,
      "learning_rate": 0.00019926672020679736,
      "loss": 1.633,
      "step": 290
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.9030426740646362,
      "learning_rate": 0.00019918717973110072,
      "loss": 2.0792,
      "step": 300
    },
    {
      "epoch": 0.124,
      "grad_norm": 1.5642791986465454,
      "learning_rate": 0.0001991035620589349,
      "loss": 1.5047,
      "step": 310
    },
    {
      "epoch": 0.128,
      "grad_norm": 2.054460048675537,
      "learning_rate": 0.000199015870627495,
      "loss": 1.6355,
      "step": 320
    },
    {
      "epoch": 0.132,
      "grad_norm": 2.1825244426727295,
      "learning_rate": 0.00019892410904143222,
      "loss": 1.5409,
      "step": 330
    },
    {
      "epoch": 0.136,
      "grad_norm": 1.5228831768035889,
      "learning_rate": 0.00019882828107270598,
      "loss": 1.8481,
      "step": 340
    },
    {
      "epoch": 0.14,
      "grad_norm": 5.09263801574707,
      "learning_rate": 0.00019872839066042874,
      "loss": 1.7745,
      "step": 350
    },
    {
      "epoch": 0.144,
      "grad_norm": 3.2239630222320557,
      "learning_rate": 0.00019862444191070408,
      "loss": 1.6073,
      "step": 360
    },
    {
      "epoch": 0.148,
      "grad_norm": 1.4044709205627441,
      "learning_rate": 0.00019851643909645804,
      "loss": 1.5039,
      "step": 370
    },
    {
      "epoch": 0.152,
      "grad_norm": 3.51741623878479,
      "learning_rate": 0.0001984043866572632,
      "loss": 1.6572,
      "step": 380
    },
    {
      "epoch": 0.156,
      "grad_norm": 0.8841949105262756,
      "learning_rate": 0.0001982882891991565,
      "loss": 1.6853,
      "step": 390
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.8144136667251587,
      "learning_rate": 0.00019816815149444977,
      "loss": 1.5475,
      "step": 400
    },
    {
      "epoch": 0.164,
      "grad_norm": 0.8289576768875122,
      "learning_rate": 0.00019804397848153342,
      "loss": 1.5933,
      "step": 410
    },
    {
      "epoch": 0.168,
      "grad_norm": 0.7508878111839294,
      "learning_rate": 0.0001979157752646737,
      "loss": 1.3729,
      "step": 420
    },
    {
      "epoch": 0.172,
      "grad_norm": 2.1276731491088867,
      "learning_rate": 0.0001977835471138027,
      "loss": 1.536,
      "step": 430
    },
    {
      "epoch": 0.176,
      "grad_norm": 1.8165258169174194,
      "learning_rate": 0.00019764729946430184,
      "loss": 1.7872,
      "step": 440
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.383781909942627,
      "learning_rate": 0.00019750703791677828,
      "loss": 1.4654,
      "step": 450
    },
    {
      "epoch": 0.184,
      "grad_norm": 5.184279918670654,
      "learning_rate": 0.0001973627682368349,
      "loss": 1.4823,
      "step": 460
    },
    {
      "epoch": 0.188,
      "grad_norm": 2.337721109390259,
      "learning_rate": 0.0001972144963548332,
      "loss": 1.64,
      "step": 470
    },
    {
      "epoch": 0.192,
      "grad_norm": 1.0584999322891235,
      "learning_rate": 0.00019706222836564952,
      "loss": 1.4945,
      "step": 480
    },
    {
      "epoch": 0.196,
      "grad_norm": 2.0738327503204346,
      "learning_rate": 0.00019690597052842446,
      "loss": 1.5313,
      "step": 490
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.115068197250366,
      "learning_rate": 0.00019674572926630567,
      "loss": 1.6322,
      "step": 500
    },
    {
      "epoch": 0.204,
      "grad_norm": 1.3315216302871704,
      "learning_rate": 0.00019658151116618385,
      "loss": 1.5415,
      "step": 510
    },
    {
      "epoch": 0.208,
      "grad_norm": 1.3839948177337646,
      "learning_rate": 0.0001964133229784219,
      "loss": 1.435,
      "step": 520
    },
    {
      "epoch": 0.212,
      "grad_norm": 5.277719974517822,
      "learning_rate": 0.00019624117161657752,
      "loss": 1.5693,
      "step": 530
    },
    {
      "epoch": 0.216,
      "grad_norm": 1.7046406269073486,
      "learning_rate": 0.00019606506415711881,
      "loss": 1.7607,
      "step": 540
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.4589056968688965,
      "learning_rate": 0.00019588500783913375,
      "loss": 1.4566,
      "step": 550
    },
    {
      "epoch": 0.224,
      "grad_norm": 3.3946352005004883,
      "learning_rate": 0.00019570101006403226,
      "loss": 1.4359,
      "step": 560
    },
    {
      "epoch": 0.228,
      "grad_norm": 1.8414881229400635,
      "learning_rate": 0.0001955130783952423,
      "loss": 1.4338,
      "step": 570
    },
    {
      "epoch": 0.232,
      "grad_norm": 0.9358095526695251,
      "learning_rate": 0.00019532122055789864,
      "loss": 1.2068,
      "step": 580
    },
    {
      "epoch": 0.236,
      "grad_norm": 1.4463573694229126,
      "learning_rate": 0.00019512544443852557,
      "loss": 1.3874,
      "step": 590
    },
    {
      "epoch": 0.24,
      "grad_norm": 3.279111385345459,
      "learning_rate": 0.00019492575808471247,
      "loss": 1.7293,
      "step": 600
    },
    {
      "epoch": 0.244,
      "grad_norm": 1.105846881866455,
      "learning_rate": 0.00019472216970478328,
      "loss": 1.3392,
      "step": 610
    },
    {
      "epoch": 0.248,
      "grad_norm": 1.1813045740127563,
      "learning_rate": 0.0001945146876674589,
      "loss": 1.3584,
      "step": 620
    },
    {
      "epoch": 0.252,
      "grad_norm": 4.897843837738037,
      "learning_rate": 0.00019430332050151324,
      "loss": 1.6823,
      "step": 630
    },
    {
      "epoch": 0.256,
      "grad_norm": 2.2838189601898193,
      "learning_rate": 0.00019408807689542257,
      "loss": 1.509,
      "step": 640
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.1784093379974365,
      "learning_rate": 0.00019386896569700853,
      "loss": 1.3766,
      "step": 650
    },
    {
      "epoch": 0.264,
      "grad_norm": 0.8633360266685486,
      "learning_rate": 0.00019364599591307425,
      "loss": 1.4166,
      "step": 660
    },
    {
      "epoch": 0.268,
      "grad_norm": 0.9131094217300415,
      "learning_rate": 0.0001934191767090343,
      "loss": 1.2089,
      "step": 670
    },
    {
      "epoch": 0.272,
      "grad_norm": 1.5715149641036987,
      "learning_rate": 0.0001931885174085377,
      "loss": 1.7495,
      "step": 680
    },
    {
      "epoch": 0.276,
      "grad_norm": 0.6264223456382751,
      "learning_rate": 0.00019295402749308497,
      "loss": 1.7577,
      "step": 690
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.2082910537719727,
      "learning_rate": 0.00019271571660163793,
      "loss": 1.5309,
      "step": 700
    },
    {
      "epoch": 0.284,
      "grad_norm": 3.826303005218506,
      "learning_rate": 0.00019247359453022407,
      "loss": 1.5806,
      "step": 710
    },
    {
      "epoch": 0.288,
      "grad_norm": 0.7209219336509705,
      "learning_rate": 0.00019222767123153336,
      "loss": 1.4271,
      "step": 720
    },
    {
      "epoch": 0.292,
      "grad_norm": 2.2184195518493652,
      "learning_rate": 0.00019197795681450937,
      "loss": 1.452,
      "step": 730
    },
    {
      "epoch": 0.296,
      "grad_norm": 1.07893705368042,
      "learning_rate": 0.0001917244615439338,
      "loss": 1.433,
      "step": 740
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.4187618494033813,
      "learning_rate": 0.00019146719584000428,
      "loss": 1.3766,
      "step": 750
    },
    {
      "epoch": 0.304,
      "grad_norm": 2.4059064388275146,
      "learning_rate": 0.0001912061702779063,
      "loss": 1.6586,
      "step": 760
    },
    {
      "epoch": 0.308,
      "grad_norm": 1.0006306171417236,
      "learning_rate": 0.0001909413955873783,
      "loss": 1.5635,
      "step": 770
    },
    {
      "epoch": 0.312,
      "grad_norm": 1.299811601638794,
      "learning_rate": 0.00019067288265227082,
      "loss": 1.5299,
      "step": 780
    },
    {
      "epoch": 0.316,
      "grad_norm": 0.9722449779510498,
      "learning_rate": 0.00019040064251009886,
      "loss": 1.2976,
      "step": 790
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.4584935903549194,
      "learning_rate": 0.00019012468635158845,
      "loss": 1.7872,
      "step": 800
    },
    {
      "epoch": 0.324,
      "grad_norm": 2.7648754119873047,
      "learning_rate": 0.00018984502552021635,
      "loss": 1.584,
      "step": 810
    },
    {
      "epoch": 0.328,
      "grad_norm": 1.7412203550338745,
      "learning_rate": 0.000189561671511744,
      "loss": 1.5812,
      "step": 820
    },
    {
      "epoch": 0.332,
      "grad_norm": 1.3458647727966309,
      "learning_rate": 0.0001892746359737449,
      "loss": 1.6313,
      "step": 830
    },
    {
      "epoch": 0.336,
      "grad_norm": 1.460942268371582,
      "learning_rate": 0.00018898393070512572,
      "loss": 1.5319,
      "step": 840
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.9537712335586548,
      "learning_rate": 0.0001886895676556415,
      "loss": 1.52,
      "step": 850
    },
    {
      "epoch": 0.344,
      "grad_norm": 2.171046257019043,
      "learning_rate": 0.00018839155892540424,
      "loss": 1.5534,
      "step": 860
    },
    {
      "epoch": 0.348,
      "grad_norm": 0.891879141330719,
      "learning_rate": 0.0001880899167643856,
      "loss": 1.3827,
      "step": 870
    },
    {
      "epoch": 0.352,
      "grad_norm": 3.126929521560669,
      "learning_rate": 0.0001877846535719134,
      "loss": 1.618,
      "step": 880
    },
    {
      "epoch": 0.356,
      "grad_norm": 2.0574615001678467,
      "learning_rate": 0.0001874757818961618,
      "loss": 1.6419,
      "step": 890
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.8916999101638794,
      "learning_rate": 0.00018716331443363563,
      "loss": 1.3158,
      "step": 900
    },
    {
      "epoch": 0.364,
      "grad_norm": 0.4915868639945984,
      "learning_rate": 0.0001868472640286485,
      "loss": 1.276,
      "step": 910
    },
    {
      "epoch": 0.368,
      "grad_norm": 7.387997150421143,
      "learning_rate": 0.00018652764367279461,
      "loss": 1.6373,
      "step": 920
    },
    {
      "epoch": 0.372,
      "grad_norm": 2.565603733062744,
      "learning_rate": 0.0001862044665044149,
      "loss": 1.6126,
      "step": 930
    },
    {
      "epoch": 0.376,
      "grad_norm": 1.8439942598342896,
      "learning_rate": 0.00018587774580805703,
      "loss": 1.4384,
      "step": 940
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.3556010723114014,
      "learning_rate": 0.0001855474950139291,
      "loss": 1.3861,
      "step": 950
    },
    {
      "epoch": 0.384,
      "grad_norm": 3.6868979930877686,
      "learning_rate": 0.00018521372769734774,
      "loss": 1.4213,
      "step": 960
    },
    {
      "epoch": 0.388,
      "grad_norm": 2.39813232421875,
      "learning_rate": 0.00018487645757818015,
      "loss": 1.486,
      "step": 970
    },
    {
      "epoch": 0.392,
      "grad_norm": 0.8430299758911133,
      "learning_rate": 0.0001845356985202798,
      "loss": 1.4516,
      "step": 980
    },
    {
      "epoch": 0.396,
      "grad_norm": 1.346730351448059,
      "learning_rate": 0.00018419146453091701,
      "loss": 1.4761,
      "step": 990
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.6636066436767578,
      "learning_rate": 0.00018384376976020276,
      "loss": 1.4382,
      "step": 1000
    },
    {
      "epoch": 0.404,
      "grad_norm": 1.3363045454025269,
      "learning_rate": 0.00018349262850050722,
      "loss": 1.4557,
      "step": 1010
    },
    {
      "epoch": 0.408,
      "grad_norm": 3.7786483764648438,
      "learning_rate": 0.00018313805518587232,
      "loss": 1.3329,
      "step": 1020
    },
    {
      "epoch": 0.412,
      "grad_norm": 0.9776219129562378,
      "learning_rate": 0.0001827800643914182,
      "loss": 1.4729,
      "step": 1030
    },
    {
      "epoch": 0.416,
      "grad_norm": 2.0280978679656982,
      "learning_rate": 0.0001824186708327443,
      "loss": 1.222,
      "step": 1040
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.7734864354133606,
      "learning_rate": 0.0001820538893653243,
      "loss": 1.3145,
      "step": 1050
    },
    {
      "epoch": 0.424,
      "grad_norm": 2.2938854694366455,
      "learning_rate": 0.00018168573498389564,
      "loss": 1.188,
      "step": 1060
    },
    {
      "epoch": 0.428,
      "grad_norm": 1.8473442792892456,
      "learning_rate": 0.00018131422282184286,
      "loss": 1.5075,
      "step": 1070
    },
    {
      "epoch": 0.432,
      "grad_norm": 3.4017581939697266,
      "learning_rate": 0.00018093936815057594,
      "loss": 1.4227,
      "step": 1080
    },
    {
      "epoch": 0.436,
      "grad_norm": 1.225844383239746,
      "learning_rate": 0.00018056118637890217,
      "loss": 1.4217,
      "step": 1090
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.6700549125671387,
      "learning_rate": 0.00018017969305239297,
      "loss": 1.3632,
      "step": 1100
    },
    {
      "epoch": 0.444,
      "grad_norm": 2.929745674133301,
      "learning_rate": 0.00017979490385274473,
      "loss": 1.4224,
      "step": 1110
    },
    {
      "epoch": 0.448,
      "grad_norm": 2.18133544921875,
      "learning_rate": 0.0001794068345971344,
      "loss": 1.2934,
      "step": 1120
    },
    {
      "epoch": 0.452,
      "grad_norm": 1.2220101356506348,
      "learning_rate": 0.00017901550123756906,
      "loss": 1.4827,
      "step": 1130
    },
    {
      "epoch": 0.456,
      "grad_norm": 1.3870185613632202,
      "learning_rate": 0.0001786209198602304,
      "loss": 1.4306,
      "step": 1140
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.0105984210968018,
      "learning_rate": 0.00017822310668481333,
      "loss": 1.4062,
      "step": 1150
    },
    {
      "epoch": 0.464,
      "grad_norm": 0.8706759810447693,
      "learning_rate": 0.00017782207806385945,
      "loss": 1.2138,
      "step": 1160
    },
    {
      "epoch": 0.468,
      "grad_norm": 1.0097064971923828,
      "learning_rate": 0.00017741785048208458,
      "loss": 1.4584,
      "step": 1170
    },
    {
      "epoch": 0.472,
      "grad_norm": 0.8852534294128418,
      "learning_rate": 0.00017701044055570136,
      "loss": 1.2945,
      "step": 1180
    },
    {
      "epoch": 0.476,
      "grad_norm": 2.1827220916748047,
      "learning_rate": 0.00017659986503173615,
      "loss": 1.61,
      "step": 1190
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.3580217361450195,
      "learning_rate": 0.00017618614078734069,
      "loss": 1.4513,
      "step": 1200
    },
    {
      "epoch": 0.484,
      "grad_norm": 6.963593006134033,
      "learning_rate": 0.00017576928482909812,
      "loss": 1.4208,
      "step": 1210
    },
    {
      "epoch": 0.488,
      "grad_norm": 3.9398324489593506,
      "learning_rate": 0.00017534931429232423,
      "loss": 1.3828,
      "step": 1220
    },
    {
      "epoch": 0.492,
      "grad_norm": 1.9872972965240479,
      "learning_rate": 0.00017492624644036285,
      "loss": 1.1996,
      "step": 1230
    },
    {
      "epoch": 0.496,
      "grad_norm": 1.0024183988571167,
      "learning_rate": 0.00017450009866387634,
      "loss": 1.5255,
      "step": 1240
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.8361837267875671,
      "learning_rate": 0.00017407088848013071,
      "loss": 1.201,
      "step": 1250
    },
    {
      "epoch": 0.504,
      "grad_norm": 3.1053545475006104,
      "learning_rate": 0.00017363863353227546,
      "loss": 1.4786,
      "step": 1260
    },
    {
      "epoch": 0.508,
      "grad_norm": 1.968544363975525,
      "learning_rate": 0.00017320335158861855,
      "loss": 1.4706,
      "step": 1270
    },
    {
      "epoch": 0.512,
      "grad_norm": 1.001348614692688,
      "learning_rate": 0.0001727650605418957,
      "loss": 1.1014,
      "step": 1280
    },
    {
      "epoch": 0.516,
      "grad_norm": 1.1906787157058716,
      "learning_rate": 0.00017232377840853522,
      "loss": 1.7147,
      "step": 1290
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.4435288906097412,
      "learning_rate": 0.00017187952332791727,
      "loss": 1.5824,
      "step": 1300
    },
    {
      "epoch": 0.524,
      "grad_norm": 1.4517748355865479,
      "learning_rate": 0.0001714323135616281,
      "loss": 1.6831,
      "step": 1310
    },
    {
      "epoch": 0.528,
      "grad_norm": 3.6160871982574463,
      "learning_rate": 0.00017098216749270967,
      "loss": 1.6844,
      "step": 1320
    },
    {
      "epoch": 0.532,
      "grad_norm": 1.0457487106323242,
      "learning_rate": 0.00017052910362490376,
      "loss": 1.4034,
      "step": 1330
    },
    {
      "epoch": 0.536,
      "grad_norm": 1.9017677307128906,
      "learning_rate": 0.0001700731405818914,
      "loss": 1.3174,
      "step": 1340
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.7176085710525513,
      "learning_rate": 0.00016961429710652746,
      "loss": 1.5534,
      "step": 1350
    },
    {
      "epoch": 0.544,
      "grad_norm": 1.1929118633270264,
      "learning_rate": 0.00016915259206007002,
      "loss": 1.3121,
      "step": 1360
    },
    {
      "epoch": 0.548,
      "grad_norm": 0.5831860303878784,
      "learning_rate": 0.00016868804442140517,
      "loss": 1.3575,
      "step": 1370
    },
    {
      "epoch": 0.552,
      "grad_norm": 1.9680525064468384,
      "learning_rate": 0.00016822067328626684,
      "loss": 1.3894,
      "step": 1380
    },
    {
      "epoch": 0.556,
      "grad_norm": 1.0704572200775146,
      "learning_rate": 0.00016775049786645177,
      "loss": 1.4327,
      "step": 1390
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.9090466499328613,
      "learning_rate": 0.00016727753748903,
      "loss": 1.1943,
      "step": 1400
    },
    {
      "epoch": 0.564,
      "grad_norm": 0.902545154094696,
      "learning_rate": 0.00016680181159555013,
      "loss": 1.476,
      "step": 1410
    },
    {
      "epoch": 0.568,
      "grad_norm": 2.748033285140991,
      "learning_rate": 0.0001663233397412404,
      "loss": 1.4098,
      "step": 1420
    },
    {
      "epoch": 0.572,
      "grad_norm": 2.057060480117798,
      "learning_rate": 0.00016584214159420463,
      "loss": 1.5587,
      "step": 1430
    },
    {
      "epoch": 0.576,
      "grad_norm": 1.0173211097717285,
      "learning_rate": 0.00016535823693461394,
      "loss": 1.2305,
      "step": 1440
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.8315314650535583,
      "learning_rate": 0.0001648716456538936,
      "loss": 1.5984,
      "step": 1450
    },
    {
      "epoch": 0.584,
      "grad_norm": 2.0302441120147705,
      "learning_rate": 0.00016438238775390526,
      "loss": 1.4016,
      "step": 1460
    },
    {
      "epoch": 0.588,
      "grad_norm": 1.3281930685043335,
      "learning_rate": 0.00016389048334612493,
      "loss": 1.5623,
      "step": 1470
    },
    {
      "epoch": 0.592,
      "grad_norm": 2.5813257694244385,
      "learning_rate": 0.0001633959526508162,
      "loss": 1.2105,
      "step": 1480
    },
    {
      "epoch": 0.596,
      "grad_norm": 2.606473684310913,
      "learning_rate": 0.00016289881599619889,
      "loss": 1.293,
      "step": 1490
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.6753194332122803,
      "learning_rate": 0.0001623990938176138,
      "loss": 1.4706,
      "step": 1500
    },
    {
      "epoch": 0.604,
      "grad_norm": 1.7082539796829224,
      "learning_rate": 0.00016189680665668242,
      "loss": 1.3814,
      "step": 1510
    },
    {
      "epoch": 0.608,
      "grad_norm": 2.3458569049835205,
      "learning_rate": 0.0001613919751604626,
      "loss": 1.0857,
      "step": 1520
    },
    {
      "epoch": 0.612,
      "grad_norm": 1.2993898391723633,
      "learning_rate": 0.00016088462008059982,
      "loss": 1.4851,
      "step": 1530
    },
    {
      "epoch": 0.616,
      "grad_norm": 2.113675832748413,
      "learning_rate": 0.00016037476227247427,
      "loss": 1.617,
      "step": 1540
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.4251325130462646,
      "learning_rate": 0.00015986242269434354,
      "loss": 1.3041,
      "step": 1550
    },
    {
      "epoch": 0.624,
      "grad_norm": 1.1263073682785034,
      "learning_rate": 0.00015934762240648085,
      "loss": 1.3016,
      "step": 1560
    },
    {
      "epoch": 0.628,
      "grad_norm": 1.232686996459961,
      "learning_rate": 0.00015883038257030976,
      "loss": 1.3004,
      "step": 1570
    },
    {
      "epoch": 0.632,
      "grad_norm": 3.882359743118286,
      "learning_rate": 0.0001583107244475341,
      "loss": 1.3501,
      "step": 1580
    },
    {
      "epoch": 0.636,
      "grad_norm": 1.6208432912826538,
      "learning_rate": 0.0001577886693992639,
      "loss": 1.3114,
      "step": 1590
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.7327466011047363,
      "learning_rate": 0.00015726423888513737,
      "loss": 1.1897,
      "step": 1600
    },
    {
      "epoch": 0.644,
      "grad_norm": 3.1010141372680664,
      "learning_rate": 0.000156737454462439,
      "loss": 1.291,
      "step": 1610
    },
    {
      "epoch": 0.648,
      "grad_norm": 3.1873507499694824,
      "learning_rate": 0.00015620833778521307,
      "loss": 1.4081,
      "step": 1620
    },
    {
      "epoch": 0.652,
      "grad_norm": 1.6985790729522705,
      "learning_rate": 0.00015567691060337378,
      "loss": 1.4853,
      "step": 1630
    },
    {
      "epoch": 0.656,
      "grad_norm": 1.6038178205490112,
      "learning_rate": 0.00015514319476181117,
      "loss": 1.2898,
      "step": 1640
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.5976592302322388,
      "learning_rate": 0.000154607212199493,
      "loss": 1.2127,
      "step": 1650
    },
    {
      "epoch": 0.664,
      "grad_norm": 3.829710006713867,
      "learning_rate": 0.00015406898494856313,
      "loss": 1.5558,
      "step": 1660
    },
    {
      "epoch": 0.668,
      "grad_norm": 1.7985687255859375,
      "learning_rate": 0.00015352853513343572,
      "loss": 1.5769,
      "step": 1670
    },
    {
      "epoch": 0.672,
      "grad_norm": 1.4667543172836304,
      "learning_rate": 0.00015298588496988596,
      "loss": 1.5362,
      "step": 1680
    },
    {
      "epoch": 0.676,
      "grad_norm": 2.4698691368103027,
      "learning_rate": 0.0001524410567641366,
      "loss": 1.4222,
      "step": 1690
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.7262383699417114,
      "learning_rate": 0.0001518940729119412,
      "loss": 1.5594,
      "step": 1700
    },
    {
      "epoch": 0.684,
      "grad_norm": 1.224015235900879,
      "learning_rate": 0.0001513449558976636,
      "loss": 1.2259,
      "step": 1710
    },
    {
      "epoch": 0.688,
      "grad_norm": 0.7717073559761047,
      "learning_rate": 0.00015079372829335347,
      "loss": 1.2538,
      "step": 1720
    },
    {
      "epoch": 0.692,
      "grad_norm": 0.5411852598190308,
      "learning_rate": 0.00015024041275781862,
      "loss": 1.5336,
      "step": 1730
    },
    {
      "epoch": 0.696,
      "grad_norm": 1.2140952348709106,
      "learning_rate": 0.00014968503203569356,
      "loss": 1.2816,
      "step": 1740
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.186733365058899,
      "learning_rate": 0.00014912760895650445,
      "loss": 1.3269,
      "step": 1750
    },
    {
      "epoch": 0.704,
      "grad_norm": 0.9411900043487549,
      "learning_rate": 0.00014856816643373083,
      "loss": 1.463,
      "step": 1760
    },
    {
      "epoch": 0.708,
      "grad_norm": 1.1804002523422241,
      "learning_rate": 0.00014800672746386365,
      "loss": 1.3961,
      "step": 1770
    },
    {
      "epoch": 0.712,
      "grad_norm": 1.173919677734375,
      "learning_rate": 0.00014744331512545988,
      "loss": 1.3045,
      "step": 1780
    },
    {
      "epoch": 0.716,
      "grad_norm": 0.8345919251441956,
      "learning_rate": 0.00014687795257819407,
      "loss": 1.4382,
      "step": 1790
    },
    {
      "epoch": 0.72,
      "grad_norm": 3.9308226108551025,
      "learning_rate": 0.00014631066306190614,
      "loss": 1.351,
      "step": 1800
    },
    {
      "epoch": 0.724,
      "grad_norm": 0.9781283736228943,
      "learning_rate": 0.0001457414698956462,
      "loss": 1.3262,
      "step": 1810
    },
    {
      "epoch": 0.728,
      "grad_norm": 2.5757157802581787,
      "learning_rate": 0.00014517039647671593,
      "loss": 1.2942,
      "step": 1820
    },
    {
      "epoch": 0.732,
      "grad_norm": 1.083965539932251,
      "learning_rate": 0.00014459746627970685,
      "loss": 1.4895,
      "step": 1830
    },
    {
      "epoch": 0.736,
      "grad_norm": 0.7997762560844421,
      "learning_rate": 0.00014402270285553535,
      "loss": 1.3182,
      "step": 1840
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.4980828762054443,
      "learning_rate": 0.00014344612983047459,
      "loss": 1.2634,
      "step": 1850
    },
    {
      "epoch": 0.744,
      "grad_norm": 1.829947829246521,
      "learning_rate": 0.00014286777090518333,
      "loss": 1.2662,
      "step": 1860
    },
    {
      "epoch": 0.748,
      "grad_norm": 0.8795732855796814,
      "learning_rate": 0.00014228764985373175,
      "loss": 1.3991,
      "step": 1870
    },
    {
      "epoch": 0.752,
      "grad_norm": 0.5093012452125549,
      "learning_rate": 0.00014170579052262406,
      "loss": 1.403,
      "step": 1880
    },
    {
      "epoch": 0.756,
      "grad_norm": 1.46115243434906,
      "learning_rate": 0.00014112221682981843,
      "loss": 1.3026,
      "step": 1890
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.522019624710083,
      "learning_rate": 0.0001405369527637436,
      "loss": 1.1484,
      "step": 1900
    },
    {
      "epoch": 0.764,
      "grad_norm": 1.4139145612716675,
      "learning_rate": 0.00013995002238231308,
      "loss": 1.4105,
      "step": 1910
    },
    {
      "epoch": 0.768,
      "grad_norm": 11.04308032989502,
      "learning_rate": 0.00013936144981193592,
      "loss": 1.4448,
      "step": 1920
    },
    {
      "epoch": 0.772,
      "grad_norm": 1.4180097579956055,
      "learning_rate": 0.00013877125924652525,
      "loss": 1.3987,
      "step": 1930
    },
    {
      "epoch": 0.776,
      "grad_norm": 0.8894153833389282,
      "learning_rate": 0.0001381794749465036,
      "loss": 1.2018,
      "step": 1940
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.8420198559761047,
      "learning_rate": 0.00013758612123780566,
      "loss": 1.2239,
      "step": 1950
    },
    {
      "epoch": 0.784,
      "grad_norm": 0.6698972582817078,
      "learning_rate": 0.00013699122251087842,
      "loss": 1.4111,
      "step": 1960
    },
    {
      "epoch": 0.788,
      "grad_norm": 1.2630467414855957,
      "learning_rate": 0.00013639480321967845,
      "loss": 1.3668,
      "step": 1970
    },
    {
      "epoch": 0.792,
      "grad_norm": 0.6840726137161255,
      "learning_rate": 0.00013579688788066684,
      "loss": 1.3914,
      "step": 1980
    },
    {
      "epoch": 0.796,
      "grad_norm": 3.763947010040283,
      "learning_rate": 0.00013519750107180125,
      "loss": 1.421,
      "step": 1990
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.331861972808838,
      "learning_rate": 0.00013459666743152577,
      "loss": 1.2342,
      "step": 2000
    },
    {
      "epoch": 0.804,
      "grad_norm": 0.6564565300941467,
      "learning_rate": 0.00013399441165775808,
      "loss": 1.2921,
      "step": 2010
    },
    {
      "epoch": 0.808,
      "grad_norm": 1.9154822826385498,
      "learning_rate": 0.00013339075850687414,
      "loss": 1.4038,
      "step": 2020
    },
    {
      "epoch": 0.812,
      "grad_norm": 1.1938068866729736,
      "learning_rate": 0.00013278573279269063,
      "loss": 1.5269,
      "step": 2030
    },
    {
      "epoch": 0.816,
      "grad_norm": 1.3147897720336914,
      "learning_rate": 0.00013217935938544497,
      "loss": 1.5001,
      "step": 2040
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.6418153643608093,
      "learning_rate": 0.00013157166321077287,
      "loss": 1.4229,
      "step": 2050
    },
    {
      "epoch": 0.824,
      "grad_norm": 1.7514050006866455,
      "learning_rate": 0.00013096266924868393,
      "loss": 1.2517,
      "step": 2060
    },
    {
      "epoch": 0.828,
      "grad_norm": 4.415118217468262,
      "learning_rate": 0.00013035240253253468,
      "loss": 1.4781,
      "step": 2070
    },
    {
      "epoch": 0.832,
      "grad_norm": 1.260333776473999,
      "learning_rate": 0.00012974088814799952,
      "loss": 1.3421,
      "step": 2080
    },
    {
      "epoch": 0.836,
      "grad_norm": 5.346252918243408,
      "learning_rate": 0.00012912815123203972,
      "loss": 1.5266,
      "step": 2090
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.5717644095420837,
      "learning_rate": 0.00012851421697186992,
      "loss": 1.2073,
      "step": 2100
    },
    {
      "epoch": 0.844,
      "grad_norm": 2.445136070251465,
      "learning_rate": 0.00012789911060392294,
      "loss": 1.3588,
      "step": 2110
    },
    {
      "epoch": 0.848,
      "grad_norm": 0.93324875831604,
      "learning_rate": 0.00012728285741281237,
      "loss": 1.2628,
      "step": 2120
    },
    {
      "epoch": 0.852,
      "grad_norm": 2.03676700592041,
      "learning_rate": 0.00012666548273029322,
      "loss": 1.5105,
      "step": 2130
    },
    {
      "epoch": 0.856,
      "grad_norm": 0.3933759927749634,
      "learning_rate": 0.0001260470119342206,
      "loss": 1.4108,
      "step": 2140
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.9751585721969604,
      "learning_rate": 0.0001254274704475065,
      "loss": 1.3586,
      "step": 2150
    },
    {
      "epoch": 0.864,
      "grad_norm": 1.4171698093414307,
      "learning_rate": 0.00012480688373707493,
      "loss": 1.4167,
      "step": 2160
    },
    {
      "epoch": 0.868,
      "grad_norm": 0.5503426194190979,
      "learning_rate": 0.0001241852773128148,
      "loss": 1.2637,
      "step": 2170
    },
    {
      "epoch": 0.872,
      "grad_norm": 0.9212702512741089,
      "learning_rate": 0.0001235626767265316,
      "loss": 1.2271,
      "step": 2180
    },
    {
      "epoch": 0.876,
      "grad_norm": 1.01658296585083,
      "learning_rate": 0.00012293910757089688,
      "loss": 1.1633,
      "step": 2190
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.3394322395324707,
      "learning_rate": 0.00012231459547839627,
      "loss": 1.4946,
      "step": 2200
    },
    {
      "epoch": 0.884,
      "grad_norm": 0.6964792013168335,
      "learning_rate": 0.00012168916612027581,
      "loss": 1.3649,
      "step": 2210
    },
    {
      "epoch": 0.888,
      "grad_norm": 0.6600357294082642,
      "learning_rate": 0.0001210628452054868,
      "loss": 1.118,
      "step": 2220
    },
    {
      "epoch": 0.892,
      "grad_norm": 1.0443928241729736,
      "learning_rate": 0.00012043565847962895,
      "loss": 1.1453,
      "step": 2230
    },
    {
      "epoch": 0.896,
      "grad_norm": 0.9108535647392273,
      "learning_rate": 0.00011980763172389197,
      "loss": 1.1928,
      "step": 2240
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.5070407390594482,
      "learning_rate": 0.000119178790753996,
      "loss": 1.4911,
      "step": 2250
    },
    {
      "epoch": 0.904,
      "grad_norm": 1.0056109428405762,
      "learning_rate": 0.00011854916141913035,
      "loss": 1.483,
      "step": 2260
    },
    {
      "epoch": 0.908,
      "grad_norm": 1.0658925771713257,
      "learning_rate": 0.00011791876960089086,
      "loss": 1.4033,
      "step": 2270
    },
    {
      "epoch": 0.912,
      "grad_norm": 1.2630685567855835,
      "learning_rate": 0.00011728764121221605,
      "loss": 1.1826,
      "step": 2280
    },
    {
      "epoch": 0.916,
      "grad_norm": 0.7019053101539612,
      "learning_rate": 0.00011665580219632208,
      "loss": 1.4103,
      "step": 2290
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.3955696821212769,
      "learning_rate": 0.00011602327852563617,
      "loss": 1.4854,
      "step": 2300
    },
    {
      "epoch": 0.924,
      "grad_norm": 2.633559465408325,
      "learning_rate": 0.00011539009620072893,
      "loss": 1.319,
      "step": 2310
    },
    {
      "epoch": 0.928,
      "grad_norm": 0.8198688626289368,
      "learning_rate": 0.00011475628124924577,
      "loss": 1.0899,
      "step": 2320
    },
    {
      "epoch": 0.932,
      "grad_norm": 1.3325400352478027,
      "learning_rate": 0.00011412185972483684,
      "loss": 1.6464,
      "step": 2330
    },
    {
      "epoch": 0.936,
      "grad_norm": 1.4340524673461914,
      "learning_rate": 0.0001134868577060862,
      "loss": 1.2232,
      "step": 2340
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.8404746055603027,
      "learning_rate": 0.00011285130129543964,
      "loss": 1.3255,
      "step": 2350
    },
    {
      "epoch": 0.944,
      "grad_norm": 1.4326735734939575,
      "learning_rate": 0.00011221521661813197,
      "loss": 1.2992,
      "step": 2360
    },
    {
      "epoch": 0.948,
      "grad_norm": 0.8859516978263855,
      "learning_rate": 0.0001115786298211128,
      "loss": 1.2611,
      "step": 2370
    },
    {
      "epoch": 0.952,
      "grad_norm": 2.1931865215301514,
      "learning_rate": 0.0001109415670719721,
      "loss": 1.6757,
      "step": 2380
    },
    {
      "epoch": 0.956,
      "grad_norm": 1.4202946424484253,
      "learning_rate": 0.00011030405455786425,
      "loss": 1.2104,
      "step": 2390
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.156833291053772,
      "learning_rate": 0.00010966611848443176,
      "loss": 1.3391,
      "step": 2400
    },
    {
      "epoch": 0.964,
      "grad_norm": 0.5887752771377563,
      "learning_rate": 0.00010902778507472799,
      "loss": 1.2773,
      "step": 2410
    },
    {
      "epoch": 0.968,
      "grad_norm": 3.3123838901519775,
      "learning_rate": 0.00010838908056813919,
      "loss": 1.2979,
      "step": 2420
    },
    {
      "epoch": 0.972,
      "grad_norm": 3.0220324993133545,
      "learning_rate": 0.00010775003121930602,
      "loss": 1.1257,
      "step": 2430
    },
    {
      "epoch": 0.976,
      "grad_norm": 0.9887374043464661,
      "learning_rate": 0.00010711066329704423,
      "loss": 1.1116,
      "step": 2440
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.1024693250656128,
      "learning_rate": 0.00010647100308326484,
      "loss": 1.2953,
      "step": 2450
    },
    {
      "epoch": 0.984,
      "grad_norm": 0.8385027647018433,
      "learning_rate": 0.00010583107687189388,
      "loss": 1.268,
      "step": 2460
    },
    {
      "epoch": 0.988,
      "grad_norm": 1.647973895072937,
      "learning_rate": 0.0001051909109677915,
      "loss": 1.2998,
      "step": 2470
    },
    {
      "epoch": 0.992,
      "grad_norm": 3.389186382293701,
      "learning_rate": 0.00010455053168567064,
      "loss": 1.4289,
      "step": 2480
    },
    {
      "epoch": 0.996,
      "grad_norm": 0.9220070242881775,
      "learning_rate": 0.00010390996534901538,
      "loss": 1.0462,
      "step": 2490
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.7397074699401855,
      "learning_rate": 0.00010326923828899894,
      "loss": 1.4156,
      "step": 2500
    },
    {
      "epoch": 1.004,
      "grad_norm": 0.9639027118682861,
      "learning_rate": 0.00010262837684340112,
      "loss": 1.4887,
      "step": 2510
    },
    {
      "epoch": 1.008,
      "grad_norm": 2.182206630706787,
      "learning_rate": 0.00010198740735552596,
      "loss": 1.2554,
      "step": 2520
    },
    {
      "epoch": 1.012,
      "grad_norm": 0.9603483080863953,
      "learning_rate": 0.00010134635617311853,
      "loss": 1.2221,
      "step": 2530
    },
    {
      "epoch": 1.016,
      "grad_norm": 3.4250192642211914,
      "learning_rate": 0.00010070524964728218,
      "loss": 1.447,
      "step": 2540
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.738854706287384,
      "learning_rate": 0.00010006411413139507,
      "loss": 1.05,
      "step": 2550
    },
    {
      "epoch": 1.024,
      "grad_norm": 1.0492695569992065,
      "learning_rate": 9.942297598002714e-05,
      "loss": 1.042,
      "step": 2560
    },
    {
      "epoch": 1.028,
      "grad_norm": 2.492426872253418,
      "learning_rate": 9.878186154785662e-05,
      "loss": 1.4666,
      "step": 2570
    },
    {
      "epoch": 1.032,
      "grad_norm": 3.1649575233459473,
      "learning_rate": 9.814079718858677e-05,
      "loss": 1.2897,
      "step": 2580
    },
    {
      "epoch": 1.036,
      "grad_norm": 0.8872597813606262,
      "learning_rate": 9.749980925386247e-05,
      "loss": 1.2416,
      "step": 2590
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.9051250219345093,
      "learning_rate": 9.685892409218717e-05,
      "loss": 1.231,
      "step": 2600
    },
    {
      "epoch": 1.044,
      "grad_norm": 0.8837795853614807,
      "learning_rate": 9.62181680478397e-05,
      "loss": 1.1985,
      "step": 2610
    },
    {
      "epoch": 1.048,
      "grad_norm": 2.122621774673462,
      "learning_rate": 9.557756745979138e-05,
      "loss": 1.1849,
      "step": 2620
    },
    {
      "epoch": 1.052,
      "grad_norm": 3.2190794944763184,
      "learning_rate": 9.493714866062326e-05,
      "loss": 1.2959,
      "step": 2630
    },
    {
      "epoch": 1.056,
      "grad_norm": NaN,
      "learning_rate": 9.436094892873858e-05,
      "loss": 1.5947,
      "step": 2640
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.6760316491127014,
      "learning_rate": 9.372094804706867e-05,
      "loss": 1.1789,
      "step": 2650
    },
    {
      "epoch": 1.064,
      "grad_norm": 2.808229684829712,
      "learning_rate": 9.308120527263117e-05,
      "loss": 1.3573,
      "step": 2660
    },
    {
      "epoch": 1.068,
      "grad_norm": 1.1165239810943604,
      "learning_rate": 9.24417469027459e-05,
      "loss": 1.185,
      "step": 2670
    },
    {
      "epoch": 1.072,
      "grad_norm": 0.9368786215782166,
      "learning_rate": 9.180259922304175e-05,
      "loss": 1.2705,
      "step": 2680
    },
    {
      "epoch": 1.076,
      "grad_norm": 2.1708762645721436,
      "learning_rate": 9.11637885063765e-05,
      "loss": 1.3303,
      "step": 2690
    },
    {
      "epoch": 1.08,
      "grad_norm": 1.931166648864746,
      "learning_rate": 9.052534101175672e-05,
      "loss": 1.2228,
      "step": 2700
    },
    {
      "epoch": 1.084,
      "grad_norm": 0.9844762086868286,
      "learning_rate": 8.988728298325822e-05,
      "loss": 1.2875,
      "step": 2710
    },
    {
      "epoch": 1.088,
      "grad_norm": 0.5643959045410156,
      "learning_rate": 8.924964064894753e-05,
      "loss": 1.1902,
      "step": 2720
    },
    {
      "epoch": 1.092,
      "grad_norm": 1.7700437307357788,
      "learning_rate": 8.861244021980344e-05,
      "loss": 1.302,
      "step": 2730
    },
    {
      "epoch": 1.096,
      "grad_norm": 1.6792892217636108,
      "learning_rate": 8.797570788863989e-05,
      "loss": 1.5425,
      "step": 2740
    },
    {
      "epoch": 1.1,
      "grad_norm": 1.2977845668792725,
      "learning_rate": 8.733946982902911e-05,
      "loss": 1.3301,
      "step": 2750
    },
    {
      "epoch": 1.104,
      "grad_norm": 0.6045295596122742,
      "learning_rate": 8.670375219422578e-05,
      "loss": 1.2757,
      "step": 2760
    },
    {
      "epoch": 1.108,
      "grad_norm": 2.2370309829711914,
      "learning_rate": 8.606858111609188e-05,
      "loss": 1.337,
      "step": 2770
    },
    {
      "epoch": 1.112,
      "grad_norm": 0.7211747765541077,
      "learning_rate": 8.543398270402266e-05,
      "loss": 1.3251,
      "step": 2780
    },
    {
      "epoch": 1.116,
      "grad_norm": 1.2359495162963867,
      "learning_rate": 8.479998304387329e-05,
      "loss": 1.456,
      "step": 2790
    },
    {
      "epoch": 1.12,
      "grad_norm": 1.6622370481491089,
      "learning_rate": 8.416660819688659e-05,
      "loss": 1.2096,
      "step": 2800
    },
    {
      "epoch": 1.124,
      "grad_norm": 2.0107059478759766,
      "learning_rate": 8.353388419862178e-05,
      "loss": 1.3181,
      "step": 2810
    },
    {
      "epoch": 1.1280000000000001,
      "grad_norm": 0.42989274859428406,
      "learning_rate": 8.290183705788419e-05,
      "loss": 1.2869,
      "step": 2820
    },
    {
      "epoch": 1.1320000000000001,
      "grad_norm": 1.6494404077529907,
      "learning_rate": 8.227049275565622e-05,
      "loss": 1.3076,
      "step": 2830
    },
    {
      "epoch": 1.1360000000000001,
      "grad_norm": 0.9478943347930908,
      "learning_rate": 8.163987724402934e-05,
      "loss": 1.2356,
      "step": 2840
    },
    {
      "epoch": 1.1400000000000001,
      "grad_norm": 1.6503478288650513,
      "learning_rate": 8.101001644513731e-05,
      "loss": 1.2827,
      "step": 2850
    },
    {
      "epoch": 1.144,
      "grad_norm": 3.3344101905822754,
      "learning_rate": 8.038093625009052e-05,
      "loss": 1.2678,
      "step": 2860
    },
    {
      "epoch": 1.148,
      "grad_norm": 2.387861490249634,
      "learning_rate": 7.975266251791185e-05,
      "loss": 1.2472,
      "step": 2870
    },
    {
      "epoch": 1.152,
      "grad_norm": 0.9998906850814819,
      "learning_rate": 7.912522107447367e-05,
      "loss": 1.226,
      "step": 2880
    },
    {
      "epoch": 1.156,
      "grad_norm": 1.958795428276062,
      "learning_rate": 7.849863771143621e-05,
      "loss": 1.2129,
      "step": 2890
    },
    {
      "epoch": 1.16,
      "grad_norm": 1.3954683542251587,
      "learning_rate": 7.787293818518738e-05,
      "loss": 1.2128,
      "step": 2900
    },
    {
      "epoch": 1.164,
      "grad_norm": 1.722585678100586,
      "learning_rate": 7.724814821578396e-05,
      "loss": 1.367,
      "step": 2910
    },
    {
      "epoch": 1.168,
      "grad_norm": 6.562158584594727,
      "learning_rate": 7.662429348589447e-05,
      "loss": 1.1775,
      "step": 2920
    },
    {
      "epoch": 1.172,
      "grad_norm": 1.7451854944229126,
      "learning_rate": 7.600139963974341e-05,
      "loss": 1.3403,
      "step": 2930
    },
    {
      "epoch": 1.176,
      "grad_norm": 1.8296914100646973,
      "learning_rate": 7.537949228205709e-05,
      "loss": 1.4728,
      "step": 2940
    },
    {
      "epoch": 1.18,
      "grad_norm": 1.8016961812973022,
      "learning_rate": 7.47585969770111e-05,
      "loss": 1.3297,
      "step": 2950
    },
    {
      "epoch": 1.184,
      "grad_norm": 1.7298575639724731,
      "learning_rate": 7.413873924717957e-05,
      "loss": 1.2714,
      "step": 2960
    },
    {
      "epoch": 1.188,
      "grad_norm": 3.7214252948760986,
      "learning_rate": 7.351994457248595e-05,
      "loss": 1.2681,
      "step": 2970
    },
    {
      "epoch": 1.192,
      "grad_norm": 0.9401415586471558,
      "learning_rate": 7.290223838915568e-05,
      "loss": 1.3549,
      "step": 2980
    },
    {
      "epoch": 1.196,
      "grad_norm": 2.476270914077759,
      "learning_rate": 7.22856460886706e-05,
      "loss": 1.5495,
      "step": 2990
    },
    {
      "epoch": 1.2,
      "grad_norm": 1.5147844552993774,
      "learning_rate": 7.167019301672509e-05,
      "loss": 1.6247,
      "step": 3000
    }
  ],
  "logging_steps": 10,
  "max_steps": 5000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 6.350846484313498e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
