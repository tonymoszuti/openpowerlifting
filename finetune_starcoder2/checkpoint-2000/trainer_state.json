{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.8,
  "eval_steps": 500,
  "global_step": 2000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.004,
      "grad_norm": 0.3426077663898468,
      "learning_rate": 2e-05,
      "loss": 2.9314,
      "step": 10
    },
    {
      "epoch": 0.008,
      "grad_norm": 0.5724144577980042,
      "learning_rate": 4e-05,
      "loss": 2.8247,
      "step": 20
    },
    {
      "epoch": 0.012,
      "grad_norm": 0.7688854336738586,
      "learning_rate": 6e-05,
      "loss": 2.5122,
      "step": 30
    },
    {
      "epoch": 0.016,
      "grad_norm": 0.8625675439834595,
      "learning_rate": 8e-05,
      "loss": 2.7368,
      "step": 40
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.1354831457138062,
      "learning_rate": 0.0001,
      "loss": 2.3019,
      "step": 50
    },
    {
      "epoch": 0.024,
      "grad_norm": 3.378488540649414,
      "learning_rate": 0.00012,
      "loss": 2.3206,
      "step": 60
    },
    {
      "epoch": 0.028,
      "grad_norm": 1.3570775985717773,
      "learning_rate": 0.00014,
      "loss": 2.0744,
      "step": 70
    },
    {
      "epoch": 0.032,
      "grad_norm": NaN,
      "learning_rate": 0.00015800000000000002,
      "loss": 1.8436,
      "step": 80
    },
    {
      "epoch": 0.036,
      "grad_norm": 4.027080535888672,
      "learning_rate": 0.00017800000000000002,
      "loss": 2.3957,
      "step": 90
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.2452301979064941,
      "learning_rate": 0.00019800000000000002,
      "loss": 2.1942,
      "step": 100
    },
    {
      "epoch": 0.044,
      "grad_norm": 4.084047317504883,
      "learning_rate": 0.0001999983352025441,
      "loss": 1.8502,
      "step": 110
    },
    {
      "epoch": 0.048,
      "grad_norm": 2.900085210800171,
      "learning_rate": 0.00019999258041830607,
      "loss": 1.8054,
      "step": 120
    },
    {
      "epoch": 0.052,
      "grad_norm": 3.3914549350738525,
      "learning_rate": 0.0001999827153307312,
      "loss": 1.9059,
      "step": 130
    },
    {
      "epoch": 0.056,
      "grad_norm": 2.0497732162475586,
      "learning_rate": 0.00019996874034533462,
      "loss": 1.496,
      "step": 140
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.8106114864349365,
      "learning_rate": 0.00019995065603657316,
      "loss": 2.0725,
      "step": 150
    },
    {
      "epoch": 0.064,
      "grad_norm": 1.7514961957931519,
      "learning_rate": 0.000199928463147822,
      "loss": 1.9731,
      "step": 160
    },
    {
      "epoch": 0.068,
      "grad_norm": 3.570523262023926,
      "learning_rate": 0.00019990216259134386,
      "loss": 1.6582,
      "step": 170
    },
    {
      "epoch": 0.072,
      "grad_norm": 1.4778298139572144,
      "learning_rate": 0.0001998717554482516,
      "loss": 2.0631,
      "step": 180
    },
    {
      "epoch": 0.076,
      "grad_norm": 4.078042507171631,
      "learning_rate": 0.00019983724296846375,
      "loss": 1.6277,
      "step": 190
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.9864320755004883,
      "learning_rate": 0.00019979862657065324,
      "loss": 1.8355,
      "step": 200
    },
    {
      "epoch": 0.084,
      "grad_norm": 2.8769729137420654,
      "learning_rate": 0.00019975590784218888,
      "loss": 1.9431,
      "step": 210
    },
    {
      "epoch": 0.088,
      "grad_norm": 4.924728870391846,
      "learning_rate": 0.00019970908853907026,
      "loss": 1.7316,
      "step": 220
    },
    {
      "epoch": 0.092,
      "grad_norm": 1.9807220697402954,
      "learning_rate": 0.00019965817058585563,
      "loss": 1.7061,
      "step": 230
    },
    {
      "epoch": 0.096,
      "grad_norm": 3.0840351581573486,
      "learning_rate": 0.00019960315607558255,
      "loss": 1.7857,
      "step": 240
    },
    {
      "epoch": 0.1,
      "grad_norm": 3.5300915241241455,
      "learning_rate": 0.0001995440472696821,
      "loss": 1.6178,
      "step": 250
    },
    {
      "epoch": 0.104,
      "grad_norm": 1.3585745096206665,
      "learning_rate": 0.00019948084659788574,
      "loss": 1.4387,
      "step": 260
    },
    {
      "epoch": 0.108,
      "grad_norm": 6.052093029022217,
      "learning_rate": 0.00019941355665812558,
      "loss": 1.8342,
      "step": 270
    },
    {
      "epoch": 0.112,
      "grad_norm": 1.362105131149292,
      "learning_rate": 0.00019934218021642748,
      "loss": 1.9202,
      "step": 280
    },
    {
      "epoch": 0.116,
      "grad_norm": 3.1927781105041504,
      "learning_rate": 0.00019926672020679736,
      "loss": 1.633,
      "step": 290
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.9030426740646362,
      "learning_rate": 0.00019918717973110072,
      "loss": 2.0792,
      "step": 300
    },
    {
      "epoch": 0.124,
      "grad_norm": 1.5642791986465454,
      "learning_rate": 0.0001991035620589349,
      "loss": 1.5047,
      "step": 310
    },
    {
      "epoch": 0.128,
      "grad_norm": 2.054460048675537,
      "learning_rate": 0.000199015870627495,
      "loss": 1.6355,
      "step": 320
    },
    {
      "epoch": 0.132,
      "grad_norm": 2.1825244426727295,
      "learning_rate": 0.00019892410904143222,
      "loss": 1.5409,
      "step": 330
    },
    {
      "epoch": 0.136,
      "grad_norm": 1.5228831768035889,
      "learning_rate": 0.00019882828107270598,
      "loss": 1.8481,
      "step": 340
    },
    {
      "epoch": 0.14,
      "grad_norm": 5.09263801574707,
      "learning_rate": 0.00019872839066042874,
      "loss": 1.7745,
      "step": 350
    },
    {
      "epoch": 0.144,
      "grad_norm": 3.2239630222320557,
      "learning_rate": 0.00019862444191070408,
      "loss": 1.6073,
      "step": 360
    },
    {
      "epoch": 0.148,
      "grad_norm": 1.4044709205627441,
      "learning_rate": 0.00019851643909645804,
      "loss": 1.5039,
      "step": 370
    },
    {
      "epoch": 0.152,
      "grad_norm": 3.51741623878479,
      "learning_rate": 0.0001984043866572632,
      "loss": 1.6572,
      "step": 380
    },
    {
      "epoch": 0.156,
      "grad_norm": 0.8841949105262756,
      "learning_rate": 0.0001982882891991565,
      "loss": 1.6853,
      "step": 390
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.8144136667251587,
      "learning_rate": 0.00019816815149444977,
      "loss": 1.5475,
      "step": 400
    },
    {
      "epoch": 0.164,
      "grad_norm": 0.8289576768875122,
      "learning_rate": 0.00019804397848153342,
      "loss": 1.5933,
      "step": 410
    },
    {
      "epoch": 0.168,
      "grad_norm": 0.7508878111839294,
      "learning_rate": 0.0001979157752646737,
      "loss": 1.3729,
      "step": 420
    },
    {
      "epoch": 0.172,
      "grad_norm": 2.1276731491088867,
      "learning_rate": 0.0001977835471138027,
      "loss": 1.536,
      "step": 430
    },
    {
      "epoch": 0.176,
      "grad_norm": 1.8165258169174194,
      "learning_rate": 0.00019764729946430184,
      "loss": 1.7872,
      "step": 440
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.383781909942627,
      "learning_rate": 0.00019750703791677828,
      "loss": 1.4654,
      "step": 450
    },
    {
      "epoch": 0.184,
      "grad_norm": 5.184279918670654,
      "learning_rate": 0.0001973627682368349,
      "loss": 1.4823,
      "step": 460
    },
    {
      "epoch": 0.188,
      "grad_norm": 2.337721109390259,
      "learning_rate": 0.0001972144963548332,
      "loss": 1.64,
      "step": 470
    },
    {
      "epoch": 0.192,
      "grad_norm": 1.0584999322891235,
      "learning_rate": 0.00019706222836564952,
      "loss": 1.4945,
      "step": 480
    },
    {
      "epoch": 0.196,
      "grad_norm": 2.0738327503204346,
      "learning_rate": 0.00019690597052842446,
      "loss": 1.5313,
      "step": 490
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.115068197250366,
      "learning_rate": 0.00019674572926630567,
      "loss": 1.6322,
      "step": 500
    },
    {
      "epoch": 0.204,
      "grad_norm": 1.3315216302871704,
      "learning_rate": 0.00019658151116618385,
      "loss": 1.5415,
      "step": 510
    },
    {
      "epoch": 0.208,
      "grad_norm": 1.3839948177337646,
      "learning_rate": 0.0001964133229784219,
      "loss": 1.435,
      "step": 520
    },
    {
      "epoch": 0.212,
      "grad_norm": 5.277719974517822,
      "learning_rate": 0.00019624117161657752,
      "loss": 1.5693,
      "step": 530
    },
    {
      "epoch": 0.216,
      "grad_norm": 1.7046406269073486,
      "learning_rate": 0.00019606506415711881,
      "loss": 1.7607,
      "step": 540
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.4589056968688965,
      "learning_rate": 0.00019588500783913375,
      "loss": 1.4566,
      "step": 550
    },
    {
      "epoch": 0.224,
      "grad_norm": 3.3946352005004883,
      "learning_rate": 0.00019570101006403226,
      "loss": 1.4359,
      "step": 560
    },
    {
      "epoch": 0.228,
      "grad_norm": 1.8414881229400635,
      "learning_rate": 0.0001955130783952423,
      "loss": 1.4338,
      "step": 570
    },
    {
      "epoch": 0.232,
      "grad_norm": 0.9358095526695251,
      "learning_rate": 0.00019532122055789864,
      "loss": 1.2068,
      "step": 580
    },
    {
      "epoch": 0.236,
      "grad_norm": 1.4463573694229126,
      "learning_rate": 0.00019512544443852557,
      "loss": 1.3874,
      "step": 590
    },
    {
      "epoch": 0.24,
      "grad_norm": 3.279111385345459,
      "learning_rate": 0.00019492575808471247,
      "loss": 1.7293,
      "step": 600
    },
    {
      "epoch": 0.244,
      "grad_norm": 1.105846881866455,
      "learning_rate": 0.00019472216970478328,
      "loss": 1.3392,
      "step": 610
    },
    {
      "epoch": 0.248,
      "grad_norm": 1.1813045740127563,
      "learning_rate": 0.0001945146876674589,
      "loss": 1.3584,
      "step": 620
    },
    {
      "epoch": 0.252,
      "grad_norm": 4.897843837738037,
      "learning_rate": 0.00019430332050151324,
      "loss": 1.6823,
      "step": 630
    },
    {
      "epoch": 0.256,
      "grad_norm": 2.2838189601898193,
      "learning_rate": 0.00019408807689542257,
      "loss": 1.509,
      "step": 640
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.1784093379974365,
      "learning_rate": 0.00019386896569700853,
      "loss": 1.3766,
      "step": 650
    },
    {
      "epoch": 0.264,
      "grad_norm": 0.8633360266685486,
      "learning_rate": 0.00019364599591307425,
      "loss": 1.4166,
      "step": 660
    },
    {
      "epoch": 0.268,
      "grad_norm": 0.9131094217300415,
      "learning_rate": 0.0001934191767090343,
      "loss": 1.2089,
      "step": 670
    },
    {
      "epoch": 0.272,
      "grad_norm": 1.5715149641036987,
      "learning_rate": 0.0001931885174085377,
      "loss": 1.7495,
      "step": 680
    },
    {
      "epoch": 0.276,
      "grad_norm": 0.6264223456382751,
      "learning_rate": 0.00019295402749308497,
      "loss": 1.7577,
      "step": 690
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.2082910537719727,
      "learning_rate": 0.00019271571660163793,
      "loss": 1.5309,
      "step": 700
    },
    {
      "epoch": 0.284,
      "grad_norm": 3.826303005218506,
      "learning_rate": 0.00019247359453022407,
      "loss": 1.5806,
      "step": 710
    },
    {
      "epoch": 0.288,
      "grad_norm": 0.7209219336509705,
      "learning_rate": 0.00019222767123153336,
      "loss": 1.4271,
      "step": 720
    },
    {
      "epoch": 0.292,
      "grad_norm": 2.2184195518493652,
      "learning_rate": 0.00019197795681450937,
      "loss": 1.452,
      "step": 730
    },
    {
      "epoch": 0.296,
      "grad_norm": 1.07893705368042,
      "learning_rate": 0.0001917244615439338,
      "loss": 1.433,
      "step": 740
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.4187618494033813,
      "learning_rate": 0.00019146719584000428,
      "loss": 1.3766,
      "step": 750
    },
    {
      "epoch": 0.304,
      "grad_norm": 2.4059064388275146,
      "learning_rate": 0.0001912061702779063,
      "loss": 1.6586,
      "step": 760
    },
    {
      "epoch": 0.308,
      "grad_norm": 1.0006306171417236,
      "learning_rate": 0.0001909413955873783,
      "loss": 1.5635,
      "step": 770
    },
    {
      "epoch": 0.312,
      "grad_norm": 1.299811601638794,
      "learning_rate": 0.00019067288265227082,
      "loss": 1.5299,
      "step": 780
    },
    {
      "epoch": 0.316,
      "grad_norm": 0.9722449779510498,
      "learning_rate": 0.00019040064251009886,
      "loss": 1.2976,
      "step": 790
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.4584935903549194,
      "learning_rate": 0.00019012468635158845,
      "loss": 1.7872,
      "step": 800
    },
    {
      "epoch": 0.324,
      "grad_norm": 2.7648754119873047,
      "learning_rate": 0.00018984502552021635,
      "loss": 1.584,
      "step": 810
    },
    {
      "epoch": 0.328,
      "grad_norm": 1.7412203550338745,
      "learning_rate": 0.000189561671511744,
      "loss": 1.5812,
      "step": 820
    },
    {
      "epoch": 0.332,
      "grad_norm": 1.3458647727966309,
      "learning_rate": 0.0001892746359737449,
      "loss": 1.6313,
      "step": 830
    },
    {
      "epoch": 0.336,
      "grad_norm": 1.460942268371582,
      "learning_rate": 0.00018898393070512572,
      "loss": 1.5319,
      "step": 840
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.9537712335586548,
      "learning_rate": 0.0001886895676556415,
      "loss": 1.52,
      "step": 850
    },
    {
      "epoch": 0.344,
      "grad_norm": 2.171046257019043,
      "learning_rate": 0.00018839155892540424,
      "loss": 1.5534,
      "step": 860
    },
    {
      "epoch": 0.348,
      "grad_norm": 0.891879141330719,
      "learning_rate": 0.0001880899167643856,
      "loss": 1.3827,
      "step": 870
    },
    {
      "epoch": 0.352,
      "grad_norm": 3.126929521560669,
      "learning_rate": 0.0001877846535719134,
      "loss": 1.618,
      "step": 880
    },
    {
      "epoch": 0.356,
      "grad_norm": 2.0574615001678467,
      "learning_rate": 0.0001874757818961618,
      "loss": 1.6419,
      "step": 890
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.8916999101638794,
      "learning_rate": 0.00018716331443363563,
      "loss": 1.3158,
      "step": 900
    },
    {
      "epoch": 0.364,
      "grad_norm": 0.4915868639945984,
      "learning_rate": 0.0001868472640286485,
      "loss": 1.276,
      "step": 910
    },
    {
      "epoch": 0.368,
      "grad_norm": 7.387997150421143,
      "learning_rate": 0.00018652764367279461,
      "loss": 1.6373,
      "step": 920
    },
    {
      "epoch": 0.372,
      "grad_norm": 2.565603733062744,
      "learning_rate": 0.0001862044665044149,
      "loss": 1.6126,
      "step": 930
    },
    {
      "epoch": 0.376,
      "grad_norm": 1.8439942598342896,
      "learning_rate": 0.00018587774580805703,
      "loss": 1.4384,
      "step": 940
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.3556010723114014,
      "learning_rate": 0.0001855474950139291,
      "loss": 1.3861,
      "step": 950
    },
    {
      "epoch": 0.384,
      "grad_norm": 3.6868979930877686,
      "learning_rate": 0.00018521372769734774,
      "loss": 1.4213,
      "step": 960
    },
    {
      "epoch": 0.388,
      "grad_norm": 2.39813232421875,
      "learning_rate": 0.00018487645757818015,
      "loss": 1.486,
      "step": 970
    },
    {
      "epoch": 0.392,
      "grad_norm": 0.8430299758911133,
      "learning_rate": 0.0001845356985202798,
      "loss": 1.4516,
      "step": 980
    },
    {
      "epoch": 0.396,
      "grad_norm": 1.346730351448059,
      "learning_rate": 0.00018419146453091701,
      "loss": 1.4761,
      "step": 990
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.6636066436767578,
      "learning_rate": 0.00018384376976020276,
      "loss": 1.4382,
      "step": 1000
    },
    {
      "epoch": 0.404,
      "grad_norm": 1.3363045454025269,
      "learning_rate": 0.00018349262850050722,
      "loss": 1.4557,
      "step": 1010
    },
    {
      "epoch": 0.408,
      "grad_norm": 3.7786483764648438,
      "learning_rate": 0.00018313805518587232,
      "loss": 1.3329,
      "step": 1020
    },
    {
      "epoch": 0.412,
      "grad_norm": 0.9776219129562378,
      "learning_rate": 0.0001827800643914182,
      "loss": 1.4729,
      "step": 1030
    },
    {
      "epoch": 0.416,
      "grad_norm": 2.0280978679656982,
      "learning_rate": 0.0001824186708327443,
      "loss": 1.222,
      "step": 1040
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.7734864354133606,
      "learning_rate": 0.0001820538893653243,
      "loss": 1.3145,
      "step": 1050
    },
    {
      "epoch": 0.424,
      "grad_norm": 2.2938854694366455,
      "learning_rate": 0.00018168573498389564,
      "loss": 1.188,
      "step": 1060
    },
    {
      "epoch": 0.428,
      "grad_norm": 1.8473442792892456,
      "learning_rate": 0.00018131422282184286,
      "loss": 1.5075,
      "step": 1070
    },
    {
      "epoch": 0.432,
      "grad_norm": 3.4017581939697266,
      "learning_rate": 0.00018093936815057594,
      "loss": 1.4227,
      "step": 1080
    },
    {
      "epoch": 0.436,
      "grad_norm": 1.225844383239746,
      "learning_rate": 0.00018056118637890217,
      "loss": 1.4217,
      "step": 1090
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.6700549125671387,
      "learning_rate": 0.00018017969305239297,
      "loss": 1.3632,
      "step": 1100
    },
    {
      "epoch": 0.444,
      "grad_norm": 2.929745674133301,
      "learning_rate": 0.00017979490385274473,
      "loss": 1.4224,
      "step": 1110
    },
    {
      "epoch": 0.448,
      "grad_norm": 2.18133544921875,
      "learning_rate": 0.0001794068345971344,
      "loss": 1.2934,
      "step": 1120
    },
    {
      "epoch": 0.452,
      "grad_norm": 1.2220101356506348,
      "learning_rate": 0.00017901550123756906,
      "loss": 1.4827,
      "step": 1130
    },
    {
      "epoch": 0.456,
      "grad_norm": 1.3870185613632202,
      "learning_rate": 0.0001786209198602304,
      "loss": 1.4306,
      "step": 1140
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.0105984210968018,
      "learning_rate": 0.00017822310668481333,
      "loss": 1.4062,
      "step": 1150
    },
    {
      "epoch": 0.464,
      "grad_norm": 0.8706759810447693,
      "learning_rate": 0.00017782207806385945,
      "loss": 1.2138,
      "step": 1160
    },
    {
      "epoch": 0.468,
      "grad_norm": 1.0097064971923828,
      "learning_rate": 0.00017741785048208458,
      "loss": 1.4584,
      "step": 1170
    },
    {
      "epoch": 0.472,
      "grad_norm": 0.8852534294128418,
      "learning_rate": 0.00017701044055570136,
      "loss": 1.2945,
      "step": 1180
    },
    {
      "epoch": 0.476,
      "grad_norm": 2.1827220916748047,
      "learning_rate": 0.00017659986503173615,
      "loss": 1.61,
      "step": 1190
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.3580217361450195,
      "learning_rate": 0.00017618614078734069,
      "loss": 1.4513,
      "step": 1200
    },
    {
      "epoch": 0.484,
      "grad_norm": 6.963593006134033,
      "learning_rate": 0.00017576928482909812,
      "loss": 1.4208,
      "step": 1210
    },
    {
      "epoch": 0.488,
      "grad_norm": 3.9398324489593506,
      "learning_rate": 0.00017534931429232423,
      "loss": 1.3828,
      "step": 1220
    },
    {
      "epoch": 0.492,
      "grad_norm": 1.9872972965240479,
      "learning_rate": 0.00017492624644036285,
      "loss": 1.1996,
      "step": 1230
    },
    {
      "epoch": 0.496,
      "grad_norm": 1.0024183988571167,
      "learning_rate": 0.00017450009866387634,
      "loss": 1.5255,
      "step": 1240
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.8361837267875671,
      "learning_rate": 0.00017407088848013071,
      "loss": 1.201,
      "step": 1250
    },
    {
      "epoch": 0.504,
      "grad_norm": 3.1053545475006104,
      "learning_rate": 0.00017363863353227546,
      "loss": 1.4786,
      "step": 1260
    },
    {
      "epoch": 0.508,
      "grad_norm": 1.968544363975525,
      "learning_rate": 0.00017320335158861855,
      "loss": 1.4706,
      "step": 1270
    },
    {
      "epoch": 0.512,
      "grad_norm": 1.001348614692688,
      "learning_rate": 0.0001727650605418957,
      "loss": 1.1014,
      "step": 1280
    },
    {
      "epoch": 0.516,
      "grad_norm": 1.1906787157058716,
      "learning_rate": 0.00017232377840853522,
      "loss": 1.7147,
      "step": 1290
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.4435288906097412,
      "learning_rate": 0.00017187952332791727,
      "loss": 1.5824,
      "step": 1300
    },
    {
      "epoch": 0.524,
      "grad_norm": 1.4517748355865479,
      "learning_rate": 0.0001714323135616281,
      "loss": 1.6831,
      "step": 1310
    },
    {
      "epoch": 0.528,
      "grad_norm": 3.6160871982574463,
      "learning_rate": 0.00017098216749270967,
      "loss": 1.6844,
      "step": 1320
    },
    {
      "epoch": 0.532,
      "grad_norm": 1.0457487106323242,
      "learning_rate": 0.00017052910362490376,
      "loss": 1.4034,
      "step": 1330
    },
    {
      "epoch": 0.536,
      "grad_norm": 1.9017677307128906,
      "learning_rate": 0.0001700731405818914,
      "loss": 1.3174,
      "step": 1340
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.7176085710525513,
      "learning_rate": 0.00016961429710652746,
      "loss": 1.5534,
      "step": 1350
    },
    {
      "epoch": 0.544,
      "grad_norm": 1.1929118633270264,
      "learning_rate": 0.00016915259206007002,
      "loss": 1.3121,
      "step": 1360
    },
    {
      "epoch": 0.548,
      "grad_norm": 0.5831860303878784,
      "learning_rate": 0.00016868804442140517,
      "loss": 1.3575,
      "step": 1370
    },
    {
      "epoch": 0.552,
      "grad_norm": 1.9680525064468384,
      "learning_rate": 0.00016822067328626684,
      "loss": 1.3894,
      "step": 1380
    },
    {
      "epoch": 0.556,
      "grad_norm": 1.0704572200775146,
      "learning_rate": 0.00016775049786645177,
      "loss": 1.4327,
      "step": 1390
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.9090466499328613,
      "learning_rate": 0.00016727753748903,
      "loss": 1.1943,
      "step": 1400
    },
    {
      "epoch": 0.564,
      "grad_norm": 0.902545154094696,
      "learning_rate": 0.00016680181159555013,
      "loss": 1.476,
      "step": 1410
    },
    {
      "epoch": 0.568,
      "grad_norm": 2.748033285140991,
      "learning_rate": 0.0001663233397412404,
      "loss": 1.4098,
      "step": 1420
    },
    {
      "epoch": 0.572,
      "grad_norm": 2.057060480117798,
      "learning_rate": 0.00016584214159420463,
      "loss": 1.5587,
      "step": 1430
    },
    {
      "epoch": 0.576,
      "grad_norm": 1.0173211097717285,
      "learning_rate": 0.00016535823693461394,
      "loss": 1.2305,
      "step": 1440
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.8315314650535583,
      "learning_rate": 0.0001648716456538936,
      "loss": 1.5984,
      "step": 1450
    },
    {
      "epoch": 0.584,
      "grad_norm": 2.0302441120147705,
      "learning_rate": 0.00016438238775390526,
      "loss": 1.4016,
      "step": 1460
    },
    {
      "epoch": 0.588,
      "grad_norm": 1.3281930685043335,
      "learning_rate": 0.00016389048334612493,
      "loss": 1.5623,
      "step": 1470
    },
    {
      "epoch": 0.592,
      "grad_norm": 2.5813257694244385,
      "learning_rate": 0.0001633959526508162,
      "loss": 1.2105,
      "step": 1480
    },
    {
      "epoch": 0.596,
      "grad_norm": 2.606473684310913,
      "learning_rate": 0.00016289881599619889,
      "loss": 1.293,
      "step": 1490
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.6753194332122803,
      "learning_rate": 0.0001623990938176138,
      "loss": 1.4706,
      "step": 1500
    },
    {
      "epoch": 0.604,
      "grad_norm": 1.7082539796829224,
      "learning_rate": 0.00016189680665668242,
      "loss": 1.3814,
      "step": 1510
    },
    {
      "epoch": 0.608,
      "grad_norm": 2.3458569049835205,
      "learning_rate": 0.0001613919751604626,
      "loss": 1.0857,
      "step": 1520
    },
    {
      "epoch": 0.612,
      "grad_norm": 1.2993898391723633,
      "learning_rate": 0.00016088462008059982,
      "loss": 1.4851,
      "step": 1530
    },
    {
      "epoch": 0.616,
      "grad_norm": 2.113675832748413,
      "learning_rate": 0.00016037476227247427,
      "loss": 1.617,
      "step": 1540
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.4251325130462646,
      "learning_rate": 0.00015986242269434354,
      "loss": 1.3041,
      "step": 1550
    },
    {
      "epoch": 0.624,
      "grad_norm": 1.1263073682785034,
      "learning_rate": 0.00015934762240648085,
      "loss": 1.3016,
      "step": 1560
    },
    {
      "epoch": 0.628,
      "grad_norm": 1.232686996459961,
      "learning_rate": 0.00015883038257030976,
      "loss": 1.3004,
      "step": 1570
    },
    {
      "epoch": 0.632,
      "grad_norm": 3.882359743118286,
      "learning_rate": 0.0001583107244475341,
      "loss": 1.3501,
      "step": 1580
    },
    {
      "epoch": 0.636,
      "grad_norm": 1.6208432912826538,
      "learning_rate": 0.0001577886693992639,
      "loss": 1.3114,
      "step": 1590
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.7327466011047363,
      "learning_rate": 0.00015726423888513737,
      "loss": 1.1897,
      "step": 1600
    },
    {
      "epoch": 0.644,
      "grad_norm": 3.1010141372680664,
      "learning_rate": 0.000156737454462439,
      "loss": 1.291,
      "step": 1610
    },
    {
      "epoch": 0.648,
      "grad_norm": 3.1873507499694824,
      "learning_rate": 0.00015620833778521307,
      "loss": 1.4081,
      "step": 1620
    },
    {
      "epoch": 0.652,
      "grad_norm": 1.6985790729522705,
      "learning_rate": 0.00015567691060337378,
      "loss": 1.4853,
      "step": 1630
    },
    {
      "epoch": 0.656,
      "grad_norm": 1.6038178205490112,
      "learning_rate": 0.00015514319476181117,
      "loss": 1.2898,
      "step": 1640
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.5976592302322388,
      "learning_rate": 0.000154607212199493,
      "loss": 1.2127,
      "step": 1650
    },
    {
      "epoch": 0.664,
      "grad_norm": 3.829710006713867,
      "learning_rate": 0.00015406898494856313,
      "loss": 1.5558,
      "step": 1660
    },
    {
      "epoch": 0.668,
      "grad_norm": 1.7985687255859375,
      "learning_rate": 0.00015352853513343572,
      "loss": 1.5769,
      "step": 1670
    },
    {
      "epoch": 0.672,
      "grad_norm": 1.4667543172836304,
      "learning_rate": 0.00015298588496988596,
      "loss": 1.5362,
      "step": 1680
    },
    {
      "epoch": 0.676,
      "grad_norm": 2.4698691368103027,
      "learning_rate": 0.0001524410567641366,
      "loss": 1.4222,
      "step": 1690
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.7262383699417114,
      "learning_rate": 0.0001518940729119412,
      "loss": 1.5594,
      "step": 1700
    },
    {
      "epoch": 0.684,
      "grad_norm": 1.224015235900879,
      "learning_rate": 0.0001513449558976636,
      "loss": 1.2259,
      "step": 1710
    },
    {
      "epoch": 0.688,
      "grad_norm": 0.7717073559761047,
      "learning_rate": 0.00015079372829335347,
      "loss": 1.2538,
      "step": 1720
    },
    {
      "epoch": 0.692,
      "grad_norm": 0.5411852598190308,
      "learning_rate": 0.00015024041275781862,
      "loss": 1.5336,
      "step": 1730
    },
    {
      "epoch": 0.696,
      "grad_norm": 1.2140952348709106,
      "learning_rate": 0.00014968503203569356,
      "loss": 1.2816,
      "step": 1740
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.186733365058899,
      "learning_rate": 0.00014912760895650445,
      "loss": 1.3269,
      "step": 1750
    },
    {
      "epoch": 0.704,
      "grad_norm": 0.9411900043487549,
      "learning_rate": 0.00014856816643373083,
      "loss": 1.463,
      "step": 1760
    },
    {
      "epoch": 0.708,
      "grad_norm": 1.1804002523422241,
      "learning_rate": 0.00014800672746386365,
      "loss": 1.3961,
      "step": 1770
    },
    {
      "epoch": 0.712,
      "grad_norm": 1.173919677734375,
      "learning_rate": 0.00014744331512545988,
      "loss": 1.3045,
      "step": 1780
    },
    {
      "epoch": 0.716,
      "grad_norm": 0.8345919251441956,
      "learning_rate": 0.00014687795257819407,
      "loss": 1.4382,
      "step": 1790
    },
    {
      "epoch": 0.72,
      "grad_norm": 3.9308226108551025,
      "learning_rate": 0.00014631066306190614,
      "loss": 1.351,
      "step": 1800
    },
    {
      "epoch": 0.724,
      "grad_norm": 0.9781283736228943,
      "learning_rate": 0.0001457414698956462,
      "loss": 1.3262,
      "step": 1810
    },
    {
      "epoch": 0.728,
      "grad_norm": 2.5757157802581787,
      "learning_rate": 0.00014517039647671593,
      "loss": 1.2942,
      "step": 1820
    },
    {
      "epoch": 0.732,
      "grad_norm": 1.083965539932251,
      "learning_rate": 0.00014459746627970685,
      "loss": 1.4895,
      "step": 1830
    },
    {
      "epoch": 0.736,
      "grad_norm": 0.7997762560844421,
      "learning_rate": 0.00014402270285553535,
      "loss": 1.3182,
      "step": 1840
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.4980828762054443,
      "learning_rate": 0.00014344612983047459,
      "loss": 1.2634,
      "step": 1850
    },
    {
      "epoch": 0.744,
      "grad_norm": 1.829947829246521,
      "learning_rate": 0.00014286777090518333,
      "loss": 1.2662,
      "step": 1860
    },
    {
      "epoch": 0.748,
      "grad_norm": 0.8795732855796814,
      "learning_rate": 0.00014228764985373175,
      "loss": 1.3991,
      "step": 1870
    },
    {
      "epoch": 0.752,
      "grad_norm": 0.5093012452125549,
      "learning_rate": 0.00014170579052262406,
      "loss": 1.403,
      "step": 1880
    },
    {
      "epoch": 0.756,
      "grad_norm": 1.46115243434906,
      "learning_rate": 0.00014112221682981843,
      "loss": 1.3026,
      "step": 1890
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.522019624710083,
      "learning_rate": 0.0001405369527637436,
      "loss": 1.1484,
      "step": 1900
    },
    {
      "epoch": 0.764,
      "grad_norm": 1.4139145612716675,
      "learning_rate": 0.00013995002238231308,
      "loss": 1.4105,
      "step": 1910
    },
    {
      "epoch": 0.768,
      "grad_norm": 11.04308032989502,
      "learning_rate": 0.00013936144981193592,
      "loss": 1.4448,
      "step": 1920
    },
    {
      "epoch": 0.772,
      "grad_norm": 1.4180097579956055,
      "learning_rate": 0.00013877125924652525,
      "loss": 1.3987,
      "step": 1930
    },
    {
      "epoch": 0.776,
      "grad_norm": 0.8894153833389282,
      "learning_rate": 0.0001381794749465036,
      "loss": 1.2018,
      "step": 1940
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.8420198559761047,
      "learning_rate": 0.00013758612123780566,
      "loss": 1.2239,
      "step": 1950
    },
    {
      "epoch": 0.784,
      "grad_norm": 0.6698972582817078,
      "learning_rate": 0.00013699122251087842,
      "loss": 1.4111,
      "step": 1960
    },
    {
      "epoch": 0.788,
      "grad_norm": 1.2630467414855957,
      "learning_rate": 0.00013639480321967845,
      "loss": 1.3668,
      "step": 1970
    },
    {
      "epoch": 0.792,
      "grad_norm": 0.6840726137161255,
      "learning_rate": 0.00013579688788066684,
      "loss": 1.3914,
      "step": 1980
    },
    {
      "epoch": 0.796,
      "grad_norm": 3.763947010040283,
      "learning_rate": 0.00013519750107180125,
      "loss": 1.421,
      "step": 1990
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.331861972808838,
      "learning_rate": 0.00013459666743152577,
      "loss": 1.2342,
      "step": 2000
    }
  ],
  "logging_steps": 10,
  "max_steps": 5000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 4.194316967371776e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
