{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.8,
  "eval_steps": 500,
  "global_step": 4500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.004,
      "grad_norm": 0.3426077663898468,
      "learning_rate": 2e-05,
      "loss": 2.9314,
      "step": 10
    },
    {
      "epoch": 0.008,
      "grad_norm": 0.5724144577980042,
      "learning_rate": 4e-05,
      "loss": 2.8247,
      "step": 20
    },
    {
      "epoch": 0.012,
      "grad_norm": 0.7688854336738586,
      "learning_rate": 6e-05,
      "loss": 2.5122,
      "step": 30
    },
    {
      "epoch": 0.016,
      "grad_norm": 0.8625675439834595,
      "learning_rate": 8e-05,
      "loss": 2.7368,
      "step": 40
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.1354831457138062,
      "learning_rate": 0.0001,
      "loss": 2.3019,
      "step": 50
    },
    {
      "epoch": 0.024,
      "grad_norm": 3.378488540649414,
      "learning_rate": 0.00012,
      "loss": 2.3206,
      "step": 60
    },
    {
      "epoch": 0.028,
      "grad_norm": 1.3570775985717773,
      "learning_rate": 0.00014,
      "loss": 2.0744,
      "step": 70
    },
    {
      "epoch": 0.032,
      "grad_norm": NaN,
      "learning_rate": 0.00015800000000000002,
      "loss": 1.8436,
      "step": 80
    },
    {
      "epoch": 0.036,
      "grad_norm": 4.027080535888672,
      "learning_rate": 0.00017800000000000002,
      "loss": 2.3957,
      "step": 90
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.2452301979064941,
      "learning_rate": 0.00019800000000000002,
      "loss": 2.1942,
      "step": 100
    },
    {
      "epoch": 0.044,
      "grad_norm": 4.084047317504883,
      "learning_rate": 0.0001999983352025441,
      "loss": 1.8502,
      "step": 110
    },
    {
      "epoch": 0.048,
      "grad_norm": 2.900085210800171,
      "learning_rate": 0.00019999258041830607,
      "loss": 1.8054,
      "step": 120
    },
    {
      "epoch": 0.052,
      "grad_norm": 3.3914549350738525,
      "learning_rate": 0.0001999827153307312,
      "loss": 1.9059,
      "step": 130
    },
    {
      "epoch": 0.056,
      "grad_norm": 2.0497732162475586,
      "learning_rate": 0.00019996874034533462,
      "loss": 1.496,
      "step": 140
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.8106114864349365,
      "learning_rate": 0.00019995065603657316,
      "loss": 2.0725,
      "step": 150
    },
    {
      "epoch": 0.064,
      "grad_norm": 1.7514961957931519,
      "learning_rate": 0.000199928463147822,
      "loss": 1.9731,
      "step": 160
    },
    {
      "epoch": 0.068,
      "grad_norm": 3.570523262023926,
      "learning_rate": 0.00019990216259134386,
      "loss": 1.6582,
      "step": 170
    },
    {
      "epoch": 0.072,
      "grad_norm": 1.4778298139572144,
      "learning_rate": 0.0001998717554482516,
      "loss": 2.0631,
      "step": 180
    },
    {
      "epoch": 0.076,
      "grad_norm": 4.078042507171631,
      "learning_rate": 0.00019983724296846375,
      "loss": 1.6277,
      "step": 190
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.9864320755004883,
      "learning_rate": 0.00019979862657065324,
      "loss": 1.8355,
      "step": 200
    },
    {
      "epoch": 0.084,
      "grad_norm": 2.8769729137420654,
      "learning_rate": 0.00019975590784218888,
      "loss": 1.9431,
      "step": 210
    },
    {
      "epoch": 0.088,
      "grad_norm": 4.924728870391846,
      "learning_rate": 0.00019970908853907026,
      "loss": 1.7316,
      "step": 220
    },
    {
      "epoch": 0.092,
      "grad_norm": 1.9807220697402954,
      "learning_rate": 0.00019965817058585563,
      "loss": 1.7061,
      "step": 230
    },
    {
      "epoch": 0.096,
      "grad_norm": 3.0840351581573486,
      "learning_rate": 0.00019960315607558255,
      "loss": 1.7857,
      "step": 240
    },
    {
      "epoch": 0.1,
      "grad_norm": 3.5300915241241455,
      "learning_rate": 0.0001995440472696821,
      "loss": 1.6178,
      "step": 250
    },
    {
      "epoch": 0.104,
      "grad_norm": 1.3585745096206665,
      "learning_rate": 0.00019948084659788574,
      "loss": 1.4387,
      "step": 260
    },
    {
      "epoch": 0.108,
      "grad_norm": 6.052093029022217,
      "learning_rate": 0.00019941355665812558,
      "loss": 1.8342,
      "step": 270
    },
    {
      "epoch": 0.112,
      "grad_norm": 1.362105131149292,
      "learning_rate": 0.00019934218021642748,
      "loss": 1.9202,
      "step": 280
    },
    {
      "epoch": 0.116,
      "grad_norm": 3.1927781105041504,
      "learning_rate": 0.00019926672020679736,
      "loss": 1.633,
      "step": 290
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.9030426740646362,
      "learning_rate": 0.00019918717973110072,
      "loss": 2.0792,
      "step": 300
    },
    {
      "epoch": 0.124,
      "grad_norm": 1.5642791986465454,
      "learning_rate": 0.0001991035620589349,
      "loss": 1.5047,
      "step": 310
    },
    {
      "epoch": 0.128,
      "grad_norm": 2.054460048675537,
      "learning_rate": 0.000199015870627495,
      "loss": 1.6355,
      "step": 320
    },
    {
      "epoch": 0.132,
      "grad_norm": 2.1825244426727295,
      "learning_rate": 0.00019892410904143222,
      "loss": 1.5409,
      "step": 330
    },
    {
      "epoch": 0.136,
      "grad_norm": 1.5228831768035889,
      "learning_rate": 0.00019882828107270598,
      "loss": 1.8481,
      "step": 340
    },
    {
      "epoch": 0.14,
      "grad_norm": 5.09263801574707,
      "learning_rate": 0.00019872839066042874,
      "loss": 1.7745,
      "step": 350
    },
    {
      "epoch": 0.144,
      "grad_norm": 3.2239630222320557,
      "learning_rate": 0.00019862444191070408,
      "loss": 1.6073,
      "step": 360
    },
    {
      "epoch": 0.148,
      "grad_norm": 1.4044709205627441,
      "learning_rate": 0.00019851643909645804,
      "loss": 1.5039,
      "step": 370
    },
    {
      "epoch": 0.152,
      "grad_norm": 3.51741623878479,
      "learning_rate": 0.0001984043866572632,
      "loss": 1.6572,
      "step": 380
    },
    {
      "epoch": 0.156,
      "grad_norm": 0.8841949105262756,
      "learning_rate": 0.0001982882891991565,
      "loss": 1.6853,
      "step": 390
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.8144136667251587,
      "learning_rate": 0.00019816815149444977,
      "loss": 1.5475,
      "step": 400
    },
    {
      "epoch": 0.164,
      "grad_norm": 0.8289576768875122,
      "learning_rate": 0.00019804397848153342,
      "loss": 1.5933,
      "step": 410
    },
    {
      "epoch": 0.168,
      "grad_norm": 0.7508878111839294,
      "learning_rate": 0.0001979157752646737,
      "loss": 1.3729,
      "step": 420
    },
    {
      "epoch": 0.172,
      "grad_norm": 2.1276731491088867,
      "learning_rate": 0.0001977835471138027,
      "loss": 1.536,
      "step": 430
    },
    {
      "epoch": 0.176,
      "grad_norm": 1.8165258169174194,
      "learning_rate": 0.00019764729946430184,
      "loss": 1.7872,
      "step": 440
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.383781909942627,
      "learning_rate": 0.00019750703791677828,
      "loss": 1.4654,
      "step": 450
    },
    {
      "epoch": 0.184,
      "grad_norm": 5.184279918670654,
      "learning_rate": 0.0001973627682368349,
      "loss": 1.4823,
      "step": 460
    },
    {
      "epoch": 0.188,
      "grad_norm": 2.337721109390259,
      "learning_rate": 0.0001972144963548332,
      "loss": 1.64,
      "step": 470
    },
    {
      "epoch": 0.192,
      "grad_norm": 1.0584999322891235,
      "learning_rate": 0.00019706222836564952,
      "loss": 1.4945,
      "step": 480
    },
    {
      "epoch": 0.196,
      "grad_norm": 2.0738327503204346,
      "learning_rate": 0.00019690597052842446,
      "loss": 1.5313,
      "step": 490
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.115068197250366,
      "learning_rate": 0.00019674572926630567,
      "loss": 1.6322,
      "step": 500
    },
    {
      "epoch": 0.204,
      "grad_norm": 1.3315216302871704,
      "learning_rate": 0.00019658151116618385,
      "loss": 1.5415,
      "step": 510
    },
    {
      "epoch": 0.208,
      "grad_norm": 1.3839948177337646,
      "learning_rate": 0.0001964133229784219,
      "loss": 1.435,
      "step": 520
    },
    {
      "epoch": 0.212,
      "grad_norm": 5.277719974517822,
      "learning_rate": 0.00019624117161657752,
      "loss": 1.5693,
      "step": 530
    },
    {
      "epoch": 0.216,
      "grad_norm": 1.7046406269073486,
      "learning_rate": 0.00019606506415711881,
      "loss": 1.7607,
      "step": 540
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.4589056968688965,
      "learning_rate": 0.00019588500783913375,
      "loss": 1.4566,
      "step": 550
    },
    {
      "epoch": 0.224,
      "grad_norm": 3.3946352005004883,
      "learning_rate": 0.00019570101006403226,
      "loss": 1.4359,
      "step": 560
    },
    {
      "epoch": 0.228,
      "grad_norm": 1.8414881229400635,
      "learning_rate": 0.0001955130783952423,
      "loss": 1.4338,
      "step": 570
    },
    {
      "epoch": 0.232,
      "grad_norm": 0.9358095526695251,
      "learning_rate": 0.00019532122055789864,
      "loss": 1.2068,
      "step": 580
    },
    {
      "epoch": 0.236,
      "grad_norm": 1.4463573694229126,
      "learning_rate": 0.00019512544443852557,
      "loss": 1.3874,
      "step": 590
    },
    {
      "epoch": 0.24,
      "grad_norm": 3.279111385345459,
      "learning_rate": 0.00019492575808471247,
      "loss": 1.7293,
      "step": 600
    },
    {
      "epoch": 0.244,
      "grad_norm": 1.105846881866455,
      "learning_rate": 0.00019472216970478328,
      "loss": 1.3392,
      "step": 610
    },
    {
      "epoch": 0.248,
      "grad_norm": 1.1813045740127563,
      "learning_rate": 0.0001945146876674589,
      "loss": 1.3584,
      "step": 620
    },
    {
      "epoch": 0.252,
      "grad_norm": 4.897843837738037,
      "learning_rate": 0.00019430332050151324,
      "loss": 1.6823,
      "step": 630
    },
    {
      "epoch": 0.256,
      "grad_norm": 2.2838189601898193,
      "learning_rate": 0.00019408807689542257,
      "loss": 1.509,
      "step": 640
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.1784093379974365,
      "learning_rate": 0.00019386896569700853,
      "loss": 1.3766,
      "step": 650
    },
    {
      "epoch": 0.264,
      "grad_norm": 0.8633360266685486,
      "learning_rate": 0.00019364599591307425,
      "loss": 1.4166,
      "step": 660
    },
    {
      "epoch": 0.268,
      "grad_norm": 0.9131094217300415,
      "learning_rate": 0.0001934191767090343,
      "loss": 1.2089,
      "step": 670
    },
    {
      "epoch": 0.272,
      "grad_norm": 1.5715149641036987,
      "learning_rate": 0.0001931885174085377,
      "loss": 1.7495,
      "step": 680
    },
    {
      "epoch": 0.276,
      "grad_norm": 0.6264223456382751,
      "learning_rate": 0.00019295402749308497,
      "loss": 1.7577,
      "step": 690
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.2082910537719727,
      "learning_rate": 0.00019271571660163793,
      "loss": 1.5309,
      "step": 700
    },
    {
      "epoch": 0.284,
      "grad_norm": 3.826303005218506,
      "learning_rate": 0.00019247359453022407,
      "loss": 1.5806,
      "step": 710
    },
    {
      "epoch": 0.288,
      "grad_norm": 0.7209219336509705,
      "learning_rate": 0.00019222767123153336,
      "loss": 1.4271,
      "step": 720
    },
    {
      "epoch": 0.292,
      "grad_norm": 2.2184195518493652,
      "learning_rate": 0.00019197795681450937,
      "loss": 1.452,
      "step": 730
    },
    {
      "epoch": 0.296,
      "grad_norm": 1.07893705368042,
      "learning_rate": 0.0001917244615439338,
      "loss": 1.433,
      "step": 740
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.4187618494033813,
      "learning_rate": 0.00019146719584000428,
      "loss": 1.3766,
      "step": 750
    },
    {
      "epoch": 0.304,
      "grad_norm": 2.4059064388275146,
      "learning_rate": 0.0001912061702779063,
      "loss": 1.6586,
      "step": 760
    },
    {
      "epoch": 0.308,
      "grad_norm": 1.0006306171417236,
      "learning_rate": 0.0001909413955873783,
      "loss": 1.5635,
      "step": 770
    },
    {
      "epoch": 0.312,
      "grad_norm": 1.299811601638794,
      "learning_rate": 0.00019067288265227082,
      "loss": 1.5299,
      "step": 780
    },
    {
      "epoch": 0.316,
      "grad_norm": 0.9722449779510498,
      "learning_rate": 0.00019040064251009886,
      "loss": 1.2976,
      "step": 790
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.4584935903549194,
      "learning_rate": 0.00019012468635158845,
      "loss": 1.7872,
      "step": 800
    },
    {
      "epoch": 0.324,
      "grad_norm": 2.7648754119873047,
      "learning_rate": 0.00018984502552021635,
      "loss": 1.584,
      "step": 810
    },
    {
      "epoch": 0.328,
      "grad_norm": 1.7412203550338745,
      "learning_rate": 0.000189561671511744,
      "loss": 1.5812,
      "step": 820
    },
    {
      "epoch": 0.332,
      "grad_norm": 1.3458647727966309,
      "learning_rate": 0.0001892746359737449,
      "loss": 1.6313,
      "step": 830
    },
    {
      "epoch": 0.336,
      "grad_norm": 1.460942268371582,
      "learning_rate": 0.00018898393070512572,
      "loss": 1.5319,
      "step": 840
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.9537712335586548,
      "learning_rate": 0.0001886895676556415,
      "loss": 1.52,
      "step": 850
    },
    {
      "epoch": 0.344,
      "grad_norm": 2.171046257019043,
      "learning_rate": 0.00018839155892540424,
      "loss": 1.5534,
      "step": 860
    },
    {
      "epoch": 0.348,
      "grad_norm": 0.891879141330719,
      "learning_rate": 0.0001880899167643856,
      "loss": 1.3827,
      "step": 870
    },
    {
      "epoch": 0.352,
      "grad_norm": 3.126929521560669,
      "learning_rate": 0.0001877846535719134,
      "loss": 1.618,
      "step": 880
    },
    {
      "epoch": 0.356,
      "grad_norm": 2.0574615001678467,
      "learning_rate": 0.0001874757818961618,
      "loss": 1.6419,
      "step": 890
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.8916999101638794,
      "learning_rate": 0.00018716331443363563,
      "loss": 1.3158,
      "step": 900
    },
    {
      "epoch": 0.364,
      "grad_norm": 0.4915868639945984,
      "learning_rate": 0.0001868472640286485,
      "loss": 1.276,
      "step": 910
    },
    {
      "epoch": 0.368,
      "grad_norm": 7.387997150421143,
      "learning_rate": 0.00018652764367279461,
      "loss": 1.6373,
      "step": 920
    },
    {
      "epoch": 0.372,
      "grad_norm": 2.565603733062744,
      "learning_rate": 0.0001862044665044149,
      "loss": 1.6126,
      "step": 930
    },
    {
      "epoch": 0.376,
      "grad_norm": 1.8439942598342896,
      "learning_rate": 0.00018587774580805703,
      "loss": 1.4384,
      "step": 940
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.3556010723114014,
      "learning_rate": 0.0001855474950139291,
      "loss": 1.3861,
      "step": 950
    },
    {
      "epoch": 0.384,
      "grad_norm": 3.6868979930877686,
      "learning_rate": 0.00018521372769734774,
      "loss": 1.4213,
      "step": 960
    },
    {
      "epoch": 0.388,
      "grad_norm": 2.39813232421875,
      "learning_rate": 0.00018487645757818015,
      "loss": 1.486,
      "step": 970
    },
    {
      "epoch": 0.392,
      "grad_norm": 0.8430299758911133,
      "learning_rate": 0.0001845356985202798,
      "loss": 1.4516,
      "step": 980
    },
    {
      "epoch": 0.396,
      "grad_norm": 1.346730351448059,
      "learning_rate": 0.00018419146453091701,
      "loss": 1.4761,
      "step": 990
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.6636066436767578,
      "learning_rate": 0.00018384376976020276,
      "loss": 1.4382,
      "step": 1000
    },
    {
      "epoch": 0.404,
      "grad_norm": 1.3363045454025269,
      "learning_rate": 0.00018349262850050722,
      "loss": 1.4557,
      "step": 1010
    },
    {
      "epoch": 0.408,
      "grad_norm": 3.7786483764648438,
      "learning_rate": 0.00018313805518587232,
      "loss": 1.3329,
      "step": 1020
    },
    {
      "epoch": 0.412,
      "grad_norm": 0.9776219129562378,
      "learning_rate": 0.0001827800643914182,
      "loss": 1.4729,
      "step": 1030
    },
    {
      "epoch": 0.416,
      "grad_norm": 2.0280978679656982,
      "learning_rate": 0.0001824186708327443,
      "loss": 1.222,
      "step": 1040
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.7734864354133606,
      "learning_rate": 0.0001820538893653243,
      "loss": 1.3145,
      "step": 1050
    },
    {
      "epoch": 0.424,
      "grad_norm": 2.2938854694366455,
      "learning_rate": 0.00018168573498389564,
      "loss": 1.188,
      "step": 1060
    },
    {
      "epoch": 0.428,
      "grad_norm": 1.8473442792892456,
      "learning_rate": 0.00018131422282184286,
      "loss": 1.5075,
      "step": 1070
    },
    {
      "epoch": 0.432,
      "grad_norm": 3.4017581939697266,
      "learning_rate": 0.00018093936815057594,
      "loss": 1.4227,
      "step": 1080
    },
    {
      "epoch": 0.436,
      "grad_norm": 1.225844383239746,
      "learning_rate": 0.00018056118637890217,
      "loss": 1.4217,
      "step": 1090
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.6700549125671387,
      "learning_rate": 0.00018017969305239297,
      "loss": 1.3632,
      "step": 1100
    },
    {
      "epoch": 0.444,
      "grad_norm": 2.929745674133301,
      "learning_rate": 0.00017979490385274473,
      "loss": 1.4224,
      "step": 1110
    },
    {
      "epoch": 0.448,
      "grad_norm": 2.18133544921875,
      "learning_rate": 0.0001794068345971344,
      "loss": 1.2934,
      "step": 1120
    },
    {
      "epoch": 0.452,
      "grad_norm": 1.2220101356506348,
      "learning_rate": 0.00017901550123756906,
      "loss": 1.4827,
      "step": 1130
    },
    {
      "epoch": 0.456,
      "grad_norm": 1.3870185613632202,
      "learning_rate": 0.0001786209198602304,
      "loss": 1.4306,
      "step": 1140
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.0105984210968018,
      "learning_rate": 0.00017822310668481333,
      "loss": 1.4062,
      "step": 1150
    },
    {
      "epoch": 0.464,
      "grad_norm": 0.8706759810447693,
      "learning_rate": 0.00017782207806385945,
      "loss": 1.2138,
      "step": 1160
    },
    {
      "epoch": 0.468,
      "grad_norm": 1.0097064971923828,
      "learning_rate": 0.00017741785048208458,
      "loss": 1.4584,
      "step": 1170
    },
    {
      "epoch": 0.472,
      "grad_norm": 0.8852534294128418,
      "learning_rate": 0.00017701044055570136,
      "loss": 1.2945,
      "step": 1180
    },
    {
      "epoch": 0.476,
      "grad_norm": 2.1827220916748047,
      "learning_rate": 0.00017659986503173615,
      "loss": 1.61,
      "step": 1190
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.3580217361450195,
      "learning_rate": 0.00017618614078734069,
      "loss": 1.4513,
      "step": 1200
    },
    {
      "epoch": 0.484,
      "grad_norm": 6.963593006134033,
      "learning_rate": 0.00017576928482909812,
      "loss": 1.4208,
      "step": 1210
    },
    {
      "epoch": 0.488,
      "grad_norm": 3.9398324489593506,
      "learning_rate": 0.00017534931429232423,
      "loss": 1.3828,
      "step": 1220
    },
    {
      "epoch": 0.492,
      "grad_norm": 1.9872972965240479,
      "learning_rate": 0.00017492624644036285,
      "loss": 1.1996,
      "step": 1230
    },
    {
      "epoch": 0.496,
      "grad_norm": 1.0024183988571167,
      "learning_rate": 0.00017450009866387634,
      "loss": 1.5255,
      "step": 1240
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.8361837267875671,
      "learning_rate": 0.00017407088848013071,
      "loss": 1.201,
      "step": 1250
    },
    {
      "epoch": 0.504,
      "grad_norm": 3.1053545475006104,
      "learning_rate": 0.00017363863353227546,
      "loss": 1.4786,
      "step": 1260
    },
    {
      "epoch": 0.508,
      "grad_norm": 1.968544363975525,
      "learning_rate": 0.00017320335158861855,
      "loss": 1.4706,
      "step": 1270
    },
    {
      "epoch": 0.512,
      "grad_norm": 1.001348614692688,
      "learning_rate": 0.0001727650605418957,
      "loss": 1.1014,
      "step": 1280
    },
    {
      "epoch": 0.516,
      "grad_norm": 1.1906787157058716,
      "learning_rate": 0.00017232377840853522,
      "loss": 1.7147,
      "step": 1290
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.4435288906097412,
      "learning_rate": 0.00017187952332791727,
      "loss": 1.5824,
      "step": 1300
    },
    {
      "epoch": 0.524,
      "grad_norm": 1.4517748355865479,
      "learning_rate": 0.0001714323135616281,
      "loss": 1.6831,
      "step": 1310
    },
    {
      "epoch": 0.528,
      "grad_norm": 3.6160871982574463,
      "learning_rate": 0.00017098216749270967,
      "loss": 1.6844,
      "step": 1320
    },
    {
      "epoch": 0.532,
      "grad_norm": 1.0457487106323242,
      "learning_rate": 0.00017052910362490376,
      "loss": 1.4034,
      "step": 1330
    },
    {
      "epoch": 0.536,
      "grad_norm": 1.9017677307128906,
      "learning_rate": 0.0001700731405818914,
      "loss": 1.3174,
      "step": 1340
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.7176085710525513,
      "learning_rate": 0.00016961429710652746,
      "loss": 1.5534,
      "step": 1350
    },
    {
      "epoch": 0.544,
      "grad_norm": 1.1929118633270264,
      "learning_rate": 0.00016915259206007002,
      "loss": 1.3121,
      "step": 1360
    },
    {
      "epoch": 0.548,
      "grad_norm": 0.5831860303878784,
      "learning_rate": 0.00016868804442140517,
      "loss": 1.3575,
      "step": 1370
    },
    {
      "epoch": 0.552,
      "grad_norm": 1.9680525064468384,
      "learning_rate": 0.00016822067328626684,
      "loss": 1.3894,
      "step": 1380
    },
    {
      "epoch": 0.556,
      "grad_norm": 1.0704572200775146,
      "learning_rate": 0.00016775049786645177,
      "loss": 1.4327,
      "step": 1390
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.9090466499328613,
      "learning_rate": 0.00016727753748903,
      "loss": 1.1943,
      "step": 1400
    },
    {
      "epoch": 0.564,
      "grad_norm": 0.902545154094696,
      "learning_rate": 0.00016680181159555013,
      "loss": 1.476,
      "step": 1410
    },
    {
      "epoch": 0.568,
      "grad_norm": 2.748033285140991,
      "learning_rate": 0.0001663233397412404,
      "loss": 1.4098,
      "step": 1420
    },
    {
      "epoch": 0.572,
      "grad_norm": 2.057060480117798,
      "learning_rate": 0.00016584214159420463,
      "loss": 1.5587,
      "step": 1430
    },
    {
      "epoch": 0.576,
      "grad_norm": 1.0173211097717285,
      "learning_rate": 0.00016535823693461394,
      "loss": 1.2305,
      "step": 1440
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.8315314650535583,
      "learning_rate": 0.0001648716456538936,
      "loss": 1.5984,
      "step": 1450
    },
    {
      "epoch": 0.584,
      "grad_norm": 2.0302441120147705,
      "learning_rate": 0.00016438238775390526,
      "loss": 1.4016,
      "step": 1460
    },
    {
      "epoch": 0.588,
      "grad_norm": 1.3281930685043335,
      "learning_rate": 0.00016389048334612493,
      "loss": 1.5623,
      "step": 1470
    },
    {
      "epoch": 0.592,
      "grad_norm": 2.5813257694244385,
      "learning_rate": 0.0001633959526508162,
      "loss": 1.2105,
      "step": 1480
    },
    {
      "epoch": 0.596,
      "grad_norm": 2.606473684310913,
      "learning_rate": 0.00016289881599619889,
      "loss": 1.293,
      "step": 1490
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.6753194332122803,
      "learning_rate": 0.0001623990938176138,
      "loss": 1.4706,
      "step": 1500
    },
    {
      "epoch": 0.604,
      "grad_norm": 1.7082539796829224,
      "learning_rate": 0.00016189680665668242,
      "loss": 1.3814,
      "step": 1510
    },
    {
      "epoch": 0.608,
      "grad_norm": 2.3458569049835205,
      "learning_rate": 0.0001613919751604626,
      "loss": 1.0857,
      "step": 1520
    },
    {
      "epoch": 0.612,
      "grad_norm": 1.2993898391723633,
      "learning_rate": 0.00016088462008059982,
      "loss": 1.4851,
      "step": 1530
    },
    {
      "epoch": 0.616,
      "grad_norm": 2.113675832748413,
      "learning_rate": 0.00016037476227247427,
      "loss": 1.617,
      "step": 1540
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.4251325130462646,
      "learning_rate": 0.00015986242269434354,
      "loss": 1.3041,
      "step": 1550
    },
    {
      "epoch": 0.624,
      "grad_norm": 1.1263073682785034,
      "learning_rate": 0.00015934762240648085,
      "loss": 1.3016,
      "step": 1560
    },
    {
      "epoch": 0.628,
      "grad_norm": 1.232686996459961,
      "learning_rate": 0.00015883038257030976,
      "loss": 1.3004,
      "step": 1570
    },
    {
      "epoch": 0.632,
      "grad_norm": 3.882359743118286,
      "learning_rate": 0.0001583107244475341,
      "loss": 1.3501,
      "step": 1580
    },
    {
      "epoch": 0.636,
      "grad_norm": 1.6208432912826538,
      "learning_rate": 0.0001577886693992639,
      "loss": 1.3114,
      "step": 1590
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.7327466011047363,
      "learning_rate": 0.00015726423888513737,
      "loss": 1.1897,
      "step": 1600
    },
    {
      "epoch": 0.644,
      "grad_norm": 3.1010141372680664,
      "learning_rate": 0.000156737454462439,
      "loss": 1.291,
      "step": 1610
    },
    {
      "epoch": 0.648,
      "grad_norm": 3.1873507499694824,
      "learning_rate": 0.00015620833778521307,
      "loss": 1.4081,
      "step": 1620
    },
    {
      "epoch": 0.652,
      "grad_norm": 1.6985790729522705,
      "learning_rate": 0.00015567691060337378,
      "loss": 1.4853,
      "step": 1630
    },
    {
      "epoch": 0.656,
      "grad_norm": 1.6038178205490112,
      "learning_rate": 0.00015514319476181117,
      "loss": 1.2898,
      "step": 1640
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.5976592302322388,
      "learning_rate": 0.000154607212199493,
      "loss": 1.2127,
      "step": 1650
    },
    {
      "epoch": 0.664,
      "grad_norm": 3.829710006713867,
      "learning_rate": 0.00015406898494856313,
      "loss": 1.5558,
      "step": 1660
    },
    {
      "epoch": 0.668,
      "grad_norm": 1.7985687255859375,
      "learning_rate": 0.00015352853513343572,
      "loss": 1.5769,
      "step": 1670
    },
    {
      "epoch": 0.672,
      "grad_norm": 1.4667543172836304,
      "learning_rate": 0.00015298588496988596,
      "loss": 1.5362,
      "step": 1680
    },
    {
      "epoch": 0.676,
      "grad_norm": 2.4698691368103027,
      "learning_rate": 0.0001524410567641366,
      "loss": 1.4222,
      "step": 1690
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.7262383699417114,
      "learning_rate": 0.0001518940729119412,
      "loss": 1.5594,
      "step": 1700
    },
    {
      "epoch": 0.684,
      "grad_norm": 1.224015235900879,
      "learning_rate": 0.0001513449558976636,
      "loss": 1.2259,
      "step": 1710
    },
    {
      "epoch": 0.688,
      "grad_norm": 0.7717073559761047,
      "learning_rate": 0.00015079372829335347,
      "loss": 1.2538,
      "step": 1720
    },
    {
      "epoch": 0.692,
      "grad_norm": 0.5411852598190308,
      "learning_rate": 0.00015024041275781862,
      "loss": 1.5336,
      "step": 1730
    },
    {
      "epoch": 0.696,
      "grad_norm": 1.2140952348709106,
      "learning_rate": 0.00014968503203569356,
      "loss": 1.2816,
      "step": 1740
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.186733365058899,
      "learning_rate": 0.00014912760895650445,
      "loss": 1.3269,
      "step": 1750
    },
    {
      "epoch": 0.704,
      "grad_norm": 0.9411900043487549,
      "learning_rate": 0.00014856816643373083,
      "loss": 1.463,
      "step": 1760
    },
    {
      "epoch": 0.708,
      "grad_norm": 1.1804002523422241,
      "learning_rate": 0.00014800672746386365,
      "loss": 1.3961,
      "step": 1770
    },
    {
      "epoch": 0.712,
      "grad_norm": 1.173919677734375,
      "learning_rate": 0.00014744331512545988,
      "loss": 1.3045,
      "step": 1780
    },
    {
      "epoch": 0.716,
      "grad_norm": 0.8345919251441956,
      "learning_rate": 0.00014687795257819407,
      "loss": 1.4382,
      "step": 1790
    },
    {
      "epoch": 0.72,
      "grad_norm": 3.9308226108551025,
      "learning_rate": 0.00014631066306190614,
      "loss": 1.351,
      "step": 1800
    },
    {
      "epoch": 0.724,
      "grad_norm": 0.9781283736228943,
      "learning_rate": 0.0001457414698956462,
      "loss": 1.3262,
      "step": 1810
    },
    {
      "epoch": 0.728,
      "grad_norm": 2.5757157802581787,
      "learning_rate": 0.00014517039647671593,
      "loss": 1.2942,
      "step": 1820
    },
    {
      "epoch": 0.732,
      "grad_norm": 1.083965539932251,
      "learning_rate": 0.00014459746627970685,
      "loss": 1.4895,
      "step": 1830
    },
    {
      "epoch": 0.736,
      "grad_norm": 0.7997762560844421,
      "learning_rate": 0.00014402270285553535,
      "loss": 1.3182,
      "step": 1840
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.4980828762054443,
      "learning_rate": 0.00014344612983047459,
      "loss": 1.2634,
      "step": 1850
    },
    {
      "epoch": 0.744,
      "grad_norm": 1.829947829246521,
      "learning_rate": 0.00014286777090518333,
      "loss": 1.2662,
      "step": 1860
    },
    {
      "epoch": 0.748,
      "grad_norm": 0.8795732855796814,
      "learning_rate": 0.00014228764985373175,
      "loss": 1.3991,
      "step": 1870
    },
    {
      "epoch": 0.752,
      "grad_norm": 0.5093012452125549,
      "learning_rate": 0.00014170579052262406,
      "loss": 1.403,
      "step": 1880
    },
    {
      "epoch": 0.756,
      "grad_norm": 1.46115243434906,
      "learning_rate": 0.00014112221682981843,
      "loss": 1.3026,
      "step": 1890
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.522019624710083,
      "learning_rate": 0.0001405369527637436,
      "loss": 1.1484,
      "step": 1900
    },
    {
      "epoch": 0.764,
      "grad_norm": 1.4139145612716675,
      "learning_rate": 0.00013995002238231308,
      "loss": 1.4105,
      "step": 1910
    },
    {
      "epoch": 0.768,
      "grad_norm": 11.04308032989502,
      "learning_rate": 0.00013936144981193592,
      "loss": 1.4448,
      "step": 1920
    },
    {
      "epoch": 0.772,
      "grad_norm": 1.4180097579956055,
      "learning_rate": 0.00013877125924652525,
      "loss": 1.3987,
      "step": 1930
    },
    {
      "epoch": 0.776,
      "grad_norm": 0.8894153833389282,
      "learning_rate": 0.0001381794749465036,
      "loss": 1.2018,
      "step": 1940
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.8420198559761047,
      "learning_rate": 0.00013758612123780566,
      "loss": 1.2239,
      "step": 1950
    },
    {
      "epoch": 0.784,
      "grad_norm": 0.6698972582817078,
      "learning_rate": 0.00013699122251087842,
      "loss": 1.4111,
      "step": 1960
    },
    {
      "epoch": 0.788,
      "grad_norm": 1.2630467414855957,
      "learning_rate": 0.00013639480321967845,
      "loss": 1.3668,
      "step": 1970
    },
    {
      "epoch": 0.792,
      "grad_norm": 0.6840726137161255,
      "learning_rate": 0.00013579688788066684,
      "loss": 1.3914,
      "step": 1980
    },
    {
      "epoch": 0.796,
      "grad_norm": 3.763947010040283,
      "learning_rate": 0.00013519750107180125,
      "loss": 1.421,
      "step": 1990
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.331861972808838,
      "learning_rate": 0.00013459666743152577,
      "loss": 1.2342,
      "step": 2000
    },
    {
      "epoch": 0.804,
      "grad_norm": 0.6564565300941467,
      "learning_rate": 0.00013399441165775808,
      "loss": 1.2921,
      "step": 2010
    },
    {
      "epoch": 0.808,
      "grad_norm": 1.9154822826385498,
      "learning_rate": 0.00013339075850687414,
      "loss": 1.4038,
      "step": 2020
    },
    {
      "epoch": 0.812,
      "grad_norm": 1.1938068866729736,
      "learning_rate": 0.00013278573279269063,
      "loss": 1.5269,
      "step": 2030
    },
    {
      "epoch": 0.816,
      "grad_norm": 1.3147897720336914,
      "learning_rate": 0.00013217935938544497,
      "loss": 1.5001,
      "step": 2040
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.6418153643608093,
      "learning_rate": 0.00013157166321077287,
      "loss": 1.4229,
      "step": 2050
    },
    {
      "epoch": 0.824,
      "grad_norm": 1.7514050006866455,
      "learning_rate": 0.00013096266924868393,
      "loss": 1.2517,
      "step": 2060
    },
    {
      "epoch": 0.828,
      "grad_norm": 4.415118217468262,
      "learning_rate": 0.00013035240253253468,
      "loss": 1.4781,
      "step": 2070
    },
    {
      "epoch": 0.832,
      "grad_norm": 1.260333776473999,
      "learning_rate": 0.00012974088814799952,
      "loss": 1.3421,
      "step": 2080
    },
    {
      "epoch": 0.836,
      "grad_norm": 5.346252918243408,
      "learning_rate": 0.00012912815123203972,
      "loss": 1.5266,
      "step": 2090
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.5717644095420837,
      "learning_rate": 0.00012851421697186992,
      "loss": 1.2073,
      "step": 2100
    },
    {
      "epoch": 0.844,
      "grad_norm": 2.445136070251465,
      "learning_rate": 0.00012789911060392294,
      "loss": 1.3588,
      "step": 2110
    },
    {
      "epoch": 0.848,
      "grad_norm": 0.93324875831604,
      "learning_rate": 0.00012728285741281237,
      "loss": 1.2628,
      "step": 2120
    },
    {
      "epoch": 0.852,
      "grad_norm": 2.03676700592041,
      "learning_rate": 0.00012666548273029322,
      "loss": 1.5105,
      "step": 2130
    },
    {
      "epoch": 0.856,
      "grad_norm": 0.3933759927749634,
      "learning_rate": 0.0001260470119342206,
      "loss": 1.4108,
      "step": 2140
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.9751585721969604,
      "learning_rate": 0.0001254274704475065,
      "loss": 1.3586,
      "step": 2150
    },
    {
      "epoch": 0.864,
      "grad_norm": 1.4171698093414307,
      "learning_rate": 0.00012480688373707493,
      "loss": 1.4167,
      "step": 2160
    },
    {
      "epoch": 0.868,
      "grad_norm": 0.5503426194190979,
      "learning_rate": 0.0001241852773128148,
      "loss": 1.2637,
      "step": 2170
    },
    {
      "epoch": 0.872,
      "grad_norm": 0.9212702512741089,
      "learning_rate": 0.0001235626767265316,
      "loss": 1.2271,
      "step": 2180
    },
    {
      "epoch": 0.876,
      "grad_norm": 1.01658296585083,
      "learning_rate": 0.00012293910757089688,
      "loss": 1.1633,
      "step": 2190
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.3394322395324707,
      "learning_rate": 0.00012231459547839627,
      "loss": 1.4946,
      "step": 2200
    },
    {
      "epoch": 0.884,
      "grad_norm": 0.6964792013168335,
      "learning_rate": 0.00012168916612027581,
      "loss": 1.3649,
      "step": 2210
    },
    {
      "epoch": 0.888,
      "grad_norm": 0.6600357294082642,
      "learning_rate": 0.0001210628452054868,
      "loss": 1.118,
      "step": 2220
    },
    {
      "epoch": 0.892,
      "grad_norm": 1.0443928241729736,
      "learning_rate": 0.00012043565847962895,
      "loss": 1.1453,
      "step": 2230
    },
    {
      "epoch": 0.896,
      "grad_norm": 0.9108535647392273,
      "learning_rate": 0.00011980763172389197,
      "loss": 1.1928,
      "step": 2240
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.5070407390594482,
      "learning_rate": 0.000119178790753996,
      "loss": 1.4911,
      "step": 2250
    },
    {
      "epoch": 0.904,
      "grad_norm": 1.0056109428405762,
      "learning_rate": 0.00011854916141913035,
      "loss": 1.483,
      "step": 2260
    },
    {
      "epoch": 0.908,
      "grad_norm": 1.0658925771713257,
      "learning_rate": 0.00011791876960089086,
      "loss": 1.4033,
      "step": 2270
    },
    {
      "epoch": 0.912,
      "grad_norm": 1.2630685567855835,
      "learning_rate": 0.00011728764121221605,
      "loss": 1.1826,
      "step": 2280
    },
    {
      "epoch": 0.916,
      "grad_norm": 0.7019053101539612,
      "learning_rate": 0.00011665580219632208,
      "loss": 1.4103,
      "step": 2290
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.3955696821212769,
      "learning_rate": 0.00011602327852563617,
      "loss": 1.4854,
      "step": 2300
    },
    {
      "epoch": 0.924,
      "grad_norm": 2.633559465408325,
      "learning_rate": 0.00011539009620072893,
      "loss": 1.319,
      "step": 2310
    },
    {
      "epoch": 0.928,
      "grad_norm": 0.8198688626289368,
      "learning_rate": 0.00011475628124924577,
      "loss": 1.0899,
      "step": 2320
    },
    {
      "epoch": 0.932,
      "grad_norm": 1.3325400352478027,
      "learning_rate": 0.00011412185972483684,
      "loss": 1.6464,
      "step": 2330
    },
    {
      "epoch": 0.936,
      "grad_norm": 1.4340524673461914,
      "learning_rate": 0.0001134868577060862,
      "loss": 1.2232,
      "step": 2340
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.8404746055603027,
      "learning_rate": 0.00011285130129543964,
      "loss": 1.3255,
      "step": 2350
    },
    {
      "epoch": 0.944,
      "grad_norm": 1.4326735734939575,
      "learning_rate": 0.00011221521661813197,
      "loss": 1.2992,
      "step": 2360
    },
    {
      "epoch": 0.948,
      "grad_norm": 0.8859516978263855,
      "learning_rate": 0.0001115786298211128,
      "loss": 1.2611,
      "step": 2370
    },
    {
      "epoch": 0.952,
      "grad_norm": 2.1931865215301514,
      "learning_rate": 0.0001109415670719721,
      "loss": 1.6757,
      "step": 2380
    },
    {
      "epoch": 0.956,
      "grad_norm": 1.4202946424484253,
      "learning_rate": 0.00011030405455786425,
      "loss": 1.2104,
      "step": 2390
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.156833291053772,
      "learning_rate": 0.00010966611848443176,
      "loss": 1.3391,
      "step": 2400
    },
    {
      "epoch": 0.964,
      "grad_norm": 0.5887752771377563,
      "learning_rate": 0.00010902778507472799,
      "loss": 1.2773,
      "step": 2410
    },
    {
      "epoch": 0.968,
      "grad_norm": 3.3123838901519775,
      "learning_rate": 0.00010838908056813919,
      "loss": 1.2979,
      "step": 2420
    },
    {
      "epoch": 0.972,
      "grad_norm": 3.0220324993133545,
      "learning_rate": 0.00010775003121930602,
      "loss": 1.1257,
      "step": 2430
    },
    {
      "epoch": 0.976,
      "grad_norm": 0.9887374043464661,
      "learning_rate": 0.00010711066329704423,
      "loss": 1.1116,
      "step": 2440
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.1024693250656128,
      "learning_rate": 0.00010647100308326484,
      "loss": 1.2953,
      "step": 2450
    },
    {
      "epoch": 0.984,
      "grad_norm": 0.8385027647018433,
      "learning_rate": 0.00010583107687189388,
      "loss": 1.268,
      "step": 2460
    },
    {
      "epoch": 0.988,
      "grad_norm": 1.647973895072937,
      "learning_rate": 0.0001051909109677915,
      "loss": 1.2998,
      "step": 2470
    },
    {
      "epoch": 0.992,
      "grad_norm": 3.389186382293701,
      "learning_rate": 0.00010455053168567064,
      "loss": 1.4289,
      "step": 2480
    },
    {
      "epoch": 0.996,
      "grad_norm": 0.9220070242881775,
      "learning_rate": 0.00010390996534901538,
      "loss": 1.0462,
      "step": 2490
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.7397074699401855,
      "learning_rate": 0.00010326923828899894,
      "loss": 1.4156,
      "step": 2500
    },
    {
      "epoch": 1.004,
      "grad_norm": 0.9639027118682861,
      "learning_rate": 0.00010262837684340112,
      "loss": 1.4887,
      "step": 2510
    },
    {
      "epoch": 1.008,
      "grad_norm": 2.182206630706787,
      "learning_rate": 0.00010198740735552596,
      "loss": 1.2554,
      "step": 2520
    },
    {
      "epoch": 1.012,
      "grad_norm": 0.9603483080863953,
      "learning_rate": 0.00010134635617311853,
      "loss": 1.2221,
      "step": 2530
    },
    {
      "epoch": 1.016,
      "grad_norm": 3.4250192642211914,
      "learning_rate": 0.00010070524964728218,
      "loss": 1.447,
      "step": 2540
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.738854706287384,
      "learning_rate": 0.00010006411413139507,
      "loss": 1.05,
      "step": 2550
    },
    {
      "epoch": 1.024,
      "grad_norm": 1.0492695569992065,
      "learning_rate": 9.942297598002714e-05,
      "loss": 1.042,
      "step": 2560
    },
    {
      "epoch": 1.028,
      "grad_norm": 2.492426872253418,
      "learning_rate": 9.878186154785662e-05,
      "loss": 1.4666,
      "step": 2570
    },
    {
      "epoch": 1.032,
      "grad_norm": 3.1649575233459473,
      "learning_rate": 9.814079718858677e-05,
      "loss": 1.2897,
      "step": 2580
    },
    {
      "epoch": 1.036,
      "grad_norm": 0.8872597813606262,
      "learning_rate": 9.749980925386247e-05,
      "loss": 1.2416,
      "step": 2590
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.9051250219345093,
      "learning_rate": 9.685892409218717e-05,
      "loss": 1.231,
      "step": 2600
    },
    {
      "epoch": 1.044,
      "grad_norm": 0.8837795853614807,
      "learning_rate": 9.62181680478397e-05,
      "loss": 1.1985,
      "step": 2610
    },
    {
      "epoch": 1.048,
      "grad_norm": 2.122621774673462,
      "learning_rate": 9.557756745979138e-05,
      "loss": 1.1849,
      "step": 2620
    },
    {
      "epoch": 1.052,
      "grad_norm": 3.2190794944763184,
      "learning_rate": 9.493714866062326e-05,
      "loss": 1.2959,
      "step": 2630
    },
    {
      "epoch": 1.056,
      "grad_norm": NaN,
      "learning_rate": 9.436094892873858e-05,
      "loss": 1.5947,
      "step": 2640
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.6760316491127014,
      "learning_rate": 9.372094804706867e-05,
      "loss": 1.1789,
      "step": 2650
    },
    {
      "epoch": 1.064,
      "grad_norm": 2.808229684829712,
      "learning_rate": 9.308120527263117e-05,
      "loss": 1.3573,
      "step": 2660
    },
    {
      "epoch": 1.068,
      "grad_norm": 1.1165239810943604,
      "learning_rate": 9.24417469027459e-05,
      "loss": 1.185,
      "step": 2670
    },
    {
      "epoch": 1.072,
      "grad_norm": 0.9368786215782166,
      "learning_rate": 9.180259922304175e-05,
      "loss": 1.2705,
      "step": 2680
    },
    {
      "epoch": 1.076,
      "grad_norm": 2.1708762645721436,
      "learning_rate": 9.11637885063765e-05,
      "loss": 1.3303,
      "step": 2690
    },
    {
      "epoch": 1.08,
      "grad_norm": 1.931166648864746,
      "learning_rate": 9.052534101175672e-05,
      "loss": 1.2228,
      "step": 2700
    },
    {
      "epoch": 1.084,
      "grad_norm": 0.9844762086868286,
      "learning_rate": 8.988728298325822e-05,
      "loss": 1.2875,
      "step": 2710
    },
    {
      "epoch": 1.088,
      "grad_norm": 0.5643959045410156,
      "learning_rate": 8.924964064894753e-05,
      "loss": 1.1902,
      "step": 2720
    },
    {
      "epoch": 1.092,
      "grad_norm": 1.7700437307357788,
      "learning_rate": 8.861244021980344e-05,
      "loss": 1.302,
      "step": 2730
    },
    {
      "epoch": 1.096,
      "grad_norm": 1.6792892217636108,
      "learning_rate": 8.797570788863989e-05,
      "loss": 1.5425,
      "step": 2740
    },
    {
      "epoch": 1.1,
      "grad_norm": 1.2977845668792725,
      "learning_rate": 8.733946982902911e-05,
      "loss": 1.3301,
      "step": 2750
    },
    {
      "epoch": 1.104,
      "grad_norm": 0.6045295596122742,
      "learning_rate": 8.670375219422578e-05,
      "loss": 1.2757,
      "step": 2760
    },
    {
      "epoch": 1.108,
      "grad_norm": 2.2370309829711914,
      "learning_rate": 8.606858111609188e-05,
      "loss": 1.337,
      "step": 2770
    },
    {
      "epoch": 1.112,
      "grad_norm": 0.7211747765541077,
      "learning_rate": 8.543398270402266e-05,
      "loss": 1.3251,
      "step": 2780
    },
    {
      "epoch": 1.116,
      "grad_norm": 1.2359495162963867,
      "learning_rate": 8.479998304387329e-05,
      "loss": 1.456,
      "step": 2790
    },
    {
      "epoch": 1.12,
      "grad_norm": 1.6622370481491089,
      "learning_rate": 8.416660819688659e-05,
      "loss": 1.2096,
      "step": 2800
    },
    {
      "epoch": 1.124,
      "grad_norm": 2.0107059478759766,
      "learning_rate": 8.353388419862178e-05,
      "loss": 1.3181,
      "step": 2810
    },
    {
      "epoch": 1.1280000000000001,
      "grad_norm": 0.42989274859428406,
      "learning_rate": 8.290183705788419e-05,
      "loss": 1.2869,
      "step": 2820
    },
    {
      "epoch": 1.1320000000000001,
      "grad_norm": 1.6494404077529907,
      "learning_rate": 8.227049275565622e-05,
      "loss": 1.3076,
      "step": 2830
    },
    {
      "epoch": 1.1360000000000001,
      "grad_norm": 0.9478943347930908,
      "learning_rate": 8.163987724402934e-05,
      "loss": 1.2356,
      "step": 2840
    },
    {
      "epoch": 1.1400000000000001,
      "grad_norm": 1.6503478288650513,
      "learning_rate": 8.101001644513731e-05,
      "loss": 1.2827,
      "step": 2850
    },
    {
      "epoch": 1.144,
      "grad_norm": 3.3344101905822754,
      "learning_rate": 8.038093625009052e-05,
      "loss": 1.2678,
      "step": 2860
    },
    {
      "epoch": 1.148,
      "grad_norm": 2.387861490249634,
      "learning_rate": 7.975266251791185e-05,
      "loss": 1.2472,
      "step": 2870
    },
    {
      "epoch": 1.152,
      "grad_norm": 0.9998906850814819,
      "learning_rate": 7.912522107447367e-05,
      "loss": 1.226,
      "step": 2880
    },
    {
      "epoch": 1.156,
      "grad_norm": 1.958795428276062,
      "learning_rate": 7.849863771143621e-05,
      "loss": 1.2129,
      "step": 2890
    },
    {
      "epoch": 1.16,
      "grad_norm": 1.3954683542251587,
      "learning_rate": 7.787293818518738e-05,
      "loss": 1.2128,
      "step": 2900
    },
    {
      "epoch": 1.164,
      "grad_norm": 1.722585678100586,
      "learning_rate": 7.724814821578396e-05,
      "loss": 1.367,
      "step": 2910
    },
    {
      "epoch": 1.168,
      "grad_norm": 6.562158584594727,
      "learning_rate": 7.662429348589447e-05,
      "loss": 1.1775,
      "step": 2920
    },
    {
      "epoch": 1.172,
      "grad_norm": 1.7451854944229126,
      "learning_rate": 7.600139963974341e-05,
      "loss": 1.3403,
      "step": 2930
    },
    {
      "epoch": 1.176,
      "grad_norm": 1.8296914100646973,
      "learning_rate": 7.537949228205709e-05,
      "loss": 1.4728,
      "step": 2940
    },
    {
      "epoch": 1.18,
      "grad_norm": 1.8016961812973022,
      "learning_rate": 7.47585969770111e-05,
      "loss": 1.3297,
      "step": 2950
    },
    {
      "epoch": 1.184,
      "grad_norm": 1.7298575639724731,
      "learning_rate": 7.413873924717957e-05,
      "loss": 1.2714,
      "step": 2960
    },
    {
      "epoch": 1.188,
      "grad_norm": 3.7214252948760986,
      "learning_rate": 7.351994457248595e-05,
      "loss": 1.2681,
      "step": 2970
    },
    {
      "epoch": 1.192,
      "grad_norm": 0.9401415586471558,
      "learning_rate": 7.290223838915568e-05,
      "loss": 1.3549,
      "step": 2980
    },
    {
      "epoch": 1.196,
      "grad_norm": 2.476270914077759,
      "learning_rate": 7.22856460886706e-05,
      "loss": 1.5495,
      "step": 2990
    },
    {
      "epoch": 1.2,
      "grad_norm": 1.5147844552993774,
      "learning_rate": 7.167019301672509e-05,
      "loss": 1.6247,
      "step": 3000
    },
    {
      "epoch": 1.204,
      "grad_norm": 0.7994626760482788,
      "learning_rate": 7.105590447218438e-05,
      "loss": 1.2005,
      "step": 3010
    },
    {
      "epoch": 1.208,
      "grad_norm": 0.7776494026184082,
      "learning_rate": 7.044280570604451e-05,
      "loss": 1.2821,
      "step": 3020
    },
    {
      "epoch": 1.212,
      "grad_norm": 1.1810953617095947,
      "learning_rate": 6.983092192039456e-05,
      "loss": 1.0409,
      "step": 3030
    },
    {
      "epoch": 1.216,
      "grad_norm": 0.7224768996238708,
      "learning_rate": 6.922027826738019e-05,
      "loss": 1.2533,
      "step": 3040
    },
    {
      "epoch": 1.22,
      "grad_norm": 2.068134069442749,
      "learning_rate": 6.861089984817032e-05,
      "loss": 1.3362,
      "step": 3050
    },
    {
      "epoch": 1.224,
      "grad_norm": 1.5544548034667969,
      "learning_rate": 6.800281171192501e-05,
      "loss": 1.3673,
      "step": 3060
    },
    {
      "epoch": 1.228,
      "grad_norm": 2.2130820751190186,
      "learning_rate": 6.739603885476582e-05,
      "loss": 1.3353,
      "step": 3070
    },
    {
      "epoch": 1.232,
      "grad_norm": 1.981311559677124,
      "learning_rate": 6.679060621874833e-05,
      "loss": 1.5654,
      "step": 3080
    },
    {
      "epoch": 1.236,
      "grad_norm": 1.4292455911636353,
      "learning_rate": 6.618653869083688e-05,
      "loss": 1.2282,
      "step": 3090
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.9447025656700134,
      "learning_rate": 6.558386110188157e-05,
      "loss": 1.1098,
      "step": 3100
    },
    {
      "epoch": 1.244,
      "grad_norm": 3.734339714050293,
      "learning_rate": 6.498259822559758e-05,
      "loss": 1.33,
      "step": 3110
    },
    {
      "epoch": 1.248,
      "grad_norm": 0.6856318712234497,
      "learning_rate": 6.438277477754679e-05,
      "loss": 1.1973,
      "step": 3120
    },
    {
      "epoch": 1.252,
      "grad_norm": 0.4415625333786011,
      "learning_rate": 6.37844154141217e-05,
      "loss": 1.1503,
      "step": 3130
    },
    {
      "epoch": 1.256,
      "grad_norm": 1.6050314903259277,
      "learning_rate": 6.318754473153221e-05,
      "loss": 1.1669,
      "step": 3140
    },
    {
      "epoch": 1.26,
      "grad_norm": 3.4674713611602783,
      "learning_rate": 6.259218726479427e-05,
      "loss": 1.2457,
      "step": 3150
    },
    {
      "epoch": 1.264,
      "grad_norm": 0.6866969466209412,
      "learning_rate": 6.199836748672153e-05,
      "loss": 1.0737,
      "step": 3160
    },
    {
      "epoch": 1.268,
      "grad_norm": 1.2081127166748047,
      "learning_rate": 6.140610980691921e-05,
      "loss": 1.1988,
      "step": 3170
    },
    {
      "epoch": 1.272,
      "grad_norm": 0.8213911056518555,
      "learning_rate": 6.081543857078076e-05,
      "loss": 1.3538,
      "step": 3180
    },
    {
      "epoch": 1.276,
      "grad_norm": 0.7381390929222107,
      "learning_rate": 6.022637805848723e-05,
      "loss": 1.1732,
      "step": 3190
    },
    {
      "epoch": 1.28,
      "grad_norm": 2.2166683673858643,
      "learning_rate": 5.9638952484009105e-05,
      "loss": 1.0812,
      "step": 3200
    },
    {
      "epoch": 1.284,
      "grad_norm": 2.6767067909240723,
      "learning_rate": 5.9053185994110974e-05,
      "loss": 1.2744,
      "step": 3210
    },
    {
      "epoch": 1.288,
      "grad_norm": 1.2022624015808105,
      "learning_rate": 5.84691026673589e-05,
      "loss": 1.2584,
      "step": 3220
    },
    {
      "epoch": 1.292,
      "grad_norm": 1.24746572971344,
      "learning_rate": 5.7886726513130784e-05,
      "loss": 1.3012,
      "step": 3230
    },
    {
      "epoch": 1.296,
      "grad_norm": 2.0228545665740967,
      "learning_rate": 5.730608147062926e-05,
      "loss": 1.3923,
      "step": 3240
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.9072334170341492,
      "learning_rate": 5.672719140789786e-05,
      "loss": 1.5083,
      "step": 3250
    },
    {
      "epoch": 1.304,
      "grad_norm": 5.430138111114502,
      "learning_rate": 5.6150080120839734e-05,
      "loss": 1.2461,
      "step": 3260
    },
    {
      "epoch": 1.308,
      "grad_norm": 1.7691644430160522,
      "learning_rate": 5.5574771332239406e-05,
      "loss": 1.5298,
      "step": 3270
    },
    {
      "epoch": 1.312,
      "grad_norm": 2.263882875442505,
      "learning_rate": 5.5001288690787886e-05,
      "loss": 1.1882,
      "step": 3280
    },
    {
      "epoch": 1.316,
      "grad_norm": 0.9530985951423645,
      "learning_rate": 5.442965577011039e-05,
      "loss": 1.1222,
      "step": 3290
    },
    {
      "epoch": 1.32,
      "grad_norm": 2.130737066268921,
      "learning_rate": 5.385989606779737e-05,
      "loss": 1.2907,
      "step": 3300
    },
    {
      "epoch": 1.324,
      "grad_norm": 0.7279485464096069,
      "learning_rate": 5.32920330044386e-05,
      "loss": 1.3759,
      "step": 3310
    },
    {
      "epoch": 1.328,
      "grad_norm": 1.3793609142303467,
      "learning_rate": 5.272608992266039e-05,
      "loss": 1.2643,
      "step": 3320
    },
    {
      "epoch": 1.332,
      "grad_norm": 3.7444915771484375,
      "learning_rate": 5.2162090086166215e-05,
      "loss": 1.7058,
      "step": 3330
    },
    {
      "epoch": 1.336,
      "grad_norm": 1.653182864189148,
      "learning_rate": 5.160005667878033e-05,
      "loss": 1.298,
      "step": 3340
    },
    {
      "epoch": 1.34,
      "grad_norm": 1.39066481590271,
      "learning_rate": 5.1040012803494795e-05,
      "loss": 1.3065,
      "step": 3350
    },
    {
      "epoch": 1.3439999999999999,
      "grad_norm": 3.046872138977051,
      "learning_rate": 5.048198148151968e-05,
      "loss": 1.312,
      "step": 3360
    },
    {
      "epoch": 1.3479999999999999,
      "grad_norm": 1.6226998567581177,
      "learning_rate": 4.992598565133709e-05,
      "loss": 0.9999,
      "step": 3370
    },
    {
      "epoch": 1.3519999999999999,
      "grad_norm": 0.5565070509910583,
      "learning_rate": 4.9372048167757876e-05,
      "loss": 1.2588,
      "step": 3380
    },
    {
      "epoch": 1.3559999999999999,
      "grad_norm": 11.271613121032715,
      "learning_rate": 4.882019180098236e-05,
      "loss": 1.4745,
      "step": 3390
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 0.8430469632148743,
      "learning_rate": 4.8270439235664344e-05,
      "loss": 1.1382,
      "step": 3400
    },
    {
      "epoch": 1.3639999999999999,
      "grad_norm": 1.7277368307113647,
      "learning_rate": 4.772281306997848e-05,
      "loss": 1.0195,
      "step": 3410
    },
    {
      "epoch": 1.3679999999999999,
      "grad_norm": 1.005626916885376,
      "learning_rate": 4.717733581469157e-05,
      "loss": 1.0699,
      "step": 3420
    },
    {
      "epoch": 1.3719999999999999,
      "grad_norm": 2.2432761192321777,
      "learning_rate": 4.66340298922371e-05,
      "loss": 1.1893,
      "step": 3430
    },
    {
      "epoch": 1.376,
      "grad_norm": 1.5641885995864868,
      "learning_rate": 4.6092917635793576e-05,
      "loss": 1.2393,
      "step": 3440
    },
    {
      "epoch": 1.38,
      "grad_norm": 1.6494944095611572,
      "learning_rate": 4.555402128836642e-05,
      "loss": 1.0592,
      "step": 3450
    },
    {
      "epoch": 1.384,
      "grad_norm": 2.059889793395996,
      "learning_rate": 4.501736300187378e-05,
      "loss": 1.3295,
      "step": 3460
    },
    {
      "epoch": 1.388,
      "grad_norm": 1.845723032951355,
      "learning_rate": 4.4482964836235875e-05,
      "loss": 1.2758,
      "step": 3470
    },
    {
      "epoch": 1.392,
      "grad_norm": 1.9018101692199707,
      "learning_rate": 4.3950848758468196e-05,
      "loss": 1.357,
      "step": 3480
    },
    {
      "epoch": 1.396,
      "grad_norm": 1.2979731559753418,
      "learning_rate": 4.3421036641778556e-05,
      "loss": 1.1942,
      "step": 3490
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.8117163181304932,
      "learning_rate": 4.2893550264667915e-05,
      "loss": 1.355,
      "step": 3500
    },
    {
      "epoch": 1.404,
      "grad_norm": 2.544800281524658,
      "learning_rate": 4.236841131003524e-05,
      "loss": 1.5052,
      "step": 3510
    },
    {
      "epoch": 1.408,
      "grad_norm": 0.6567398905754089,
      "learning_rate": 4.184564136428611e-05,
      "loss": 1.1919,
      "step": 3520
    },
    {
      "epoch": 1.412,
      "grad_norm": 0.6932273507118225,
      "learning_rate": 4.132526191644549e-05,
      "loss": 1.1993,
      "step": 3530
    },
    {
      "epoch": 1.416,
      "grad_norm": 5.500480651855469,
      "learning_rate": 4.0807294357274216e-05,
      "loss": 1.1856,
      "step": 3540
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.8666473031044006,
      "learning_rate": 4.029175997838996e-05,
      "loss": 1.438,
      "step": 3550
    },
    {
      "epoch": 1.424,
      "grad_norm": 2.0457143783569336,
      "learning_rate": 3.9778679971391785e-05,
      "loss": 1.5654,
      "step": 3560
    },
    {
      "epoch": 1.428,
      "grad_norm": 0.6601086258888245,
      "learning_rate": 3.926807542698922e-05,
      "loss": 1.1025,
      "step": 3570
    },
    {
      "epoch": 1.432,
      "grad_norm": 2.352203130722046,
      "learning_rate": 3.875996733413522e-05,
      "loss": 1.2262,
      "step": 3580
    },
    {
      "epoch": 1.436,
      "grad_norm": 1.5481921434402466,
      "learning_rate": 3.8254376579163255e-05,
      "loss": 1.265,
      "step": 3590
    },
    {
      "epoch": 1.44,
      "grad_norm": 1.0264194011688232,
      "learning_rate": 3.775132394492906e-05,
      "loss": 1.1357,
      "step": 3600
    },
    {
      "epoch": 1.444,
      "grad_norm": 3.124826431274414,
      "learning_rate": 3.725083010995611e-05,
      "loss": 1.2564,
      "step": 3610
    },
    {
      "epoch": 1.448,
      "grad_norm": 3.068493127822876,
      "learning_rate": 3.675291564758565e-05,
      "loss": 1.2434,
      "step": 3620
    },
    {
      "epoch": 1.452,
      "grad_norm": 1.1981743574142456,
      "learning_rate": 3.630701491346623e-05,
      "loss": 1.2962,
      "step": 3630
    },
    {
      "epoch": 1.456,
      "grad_norm": 0.9224603772163391,
      "learning_rate": 3.581405755817867e-05,
      "loss": 1.278,
      "step": 3640
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.9845507144927979,
      "learning_rate": 3.5323738635585754e-05,
      "loss": 1.1236,
      "step": 3650
    },
    {
      "epoch": 1.464,
      "grad_norm": 1.4830487966537476,
      "learning_rate": 3.483607830077794e-05,
      "loss": 1.3037,
      "step": 3660
    },
    {
      "epoch": 1.468,
      "grad_norm": 1.4393447637557983,
      "learning_rate": 3.4351096599561585e-05,
      "loss": 1.1348,
      "step": 3670
    },
    {
      "epoch": 1.472,
      "grad_norm": 1.3325958251953125,
      "learning_rate": 3.386881346763483e-05,
      "loss": 1.3109,
      "step": 3680
    },
    {
      "epoch": 1.476,
      "grad_norm": 1.4253904819488525,
      "learning_rate": 3.3389248729768276e-05,
      "loss": 1.256,
      "step": 3690
    },
    {
      "epoch": 1.48,
      "grad_norm": 1.4725372791290283,
      "learning_rate": 3.291242209898997e-05,
      "loss": 1.4235,
      "step": 3700
    },
    {
      "epoch": 1.484,
      "grad_norm": 1.9992882013320923,
      "learning_rate": 3.243835317577514e-05,
      "loss": 1.3144,
      "step": 3710
    },
    {
      "epoch": 1.488,
      "grad_norm": 0.7951242923736572,
      "learning_rate": 3.196706144724034e-05,
      "loss": 1.3142,
      "step": 3720
    },
    {
      "epoch": 1.492,
      "grad_norm": 3.1409542560577393,
      "learning_rate": 3.149856628634267e-05,
      "loss": 1.2619,
      "step": 3730
    },
    {
      "epoch": 1.496,
      "grad_norm": 2.1219077110290527,
      "learning_rate": 3.103288695108319e-05,
      "loss": 1.4949,
      "step": 3740
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.9007052183151245,
      "learning_rate": 3.057004258371541e-05,
      "loss": 1.4837,
      "step": 3750
    },
    {
      "epoch": 1.504,
      "grad_norm": 0.7557085752487183,
      "learning_rate": 3.011005220995854e-05,
      "loss": 1.407,
      "step": 3760
    },
    {
      "epoch": 1.508,
      "grad_norm": 0.6710970997810364,
      "learning_rate": 2.9652934738215087e-05,
      "loss": 1.3641,
      "step": 3770
    },
    {
      "epoch": 1.512,
      "grad_norm": 1.626600742340088,
      "learning_rate": 2.919870895879393e-05,
      "loss": 1.1247,
      "step": 3780
    },
    {
      "epoch": 1.516,
      "grad_norm": 3.0314924716949463,
      "learning_rate": 2.874739354313779e-05,
      "loss": 1.1544,
      "step": 3790
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.8392887115478516,
      "learning_rate": 2.8299007043055725e-05,
      "loss": 1.4462,
      "step": 3800
    },
    {
      "epoch": 1.524,
      "grad_norm": 0.9334829449653625,
      "learning_rate": 2.7853567889960564e-05,
      "loss": 1.2949,
      "step": 3810
    },
    {
      "epoch": 1.528,
      "grad_norm": 1.0488301515579224,
      "learning_rate": 2.741109439411117e-05,
      "loss": 1.5003,
      "step": 3820
    },
    {
      "epoch": 1.532,
      "grad_norm": 2.6593596935272217,
      "learning_rate": 2.6971604743859935e-05,
      "loss": 1.0637,
      "step": 3830
    },
    {
      "epoch": 1.536,
      "grad_norm": 2.9485127925872803,
      "learning_rate": 2.6535117004905018e-05,
      "loss": 1.5242,
      "step": 3840
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.5610828995704651,
      "learning_rate": 2.61016491195478e-05,
      "loss": 1.3045,
      "step": 3850
    },
    {
      "epoch": 1.544,
      "grad_norm": 1.5601493120193481,
      "learning_rate": 2.5671218905955207e-05,
      "loss": 1.3165,
      "step": 3860
    },
    {
      "epoch": 1.548,
      "grad_norm": 1.5958011150360107,
      "learning_rate": 2.5243844057427435e-05,
      "loss": 1.4452,
      "step": 3870
    },
    {
      "epoch": 1.552,
      "grad_norm": 2.2071595191955566,
      "learning_rate": 2.4819542141670648e-05,
      "loss": 1.15,
      "step": 3880
    },
    {
      "epoch": 1.556,
      "grad_norm": 1.0908464193344116,
      "learning_rate": 2.4398330600074713e-05,
      "loss": 1.1028,
      "step": 3890
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.8827077150344849,
      "learning_rate": 2.398022674699635e-05,
      "loss": 1.1176,
      "step": 3900
    },
    {
      "epoch": 1.564,
      "grad_norm": 0.8975583910942078,
      "learning_rate": 2.3565247769047292e-05,
      "loss": 1.2095,
      "step": 3910
    },
    {
      "epoch": 1.568,
      "grad_norm": 1.8655325174331665,
      "learning_rate": 2.3153410724388013e-05,
      "loss": 1.4593,
      "step": 3920
    },
    {
      "epoch": 1.572,
      "grad_norm": 2.191416025161743,
      "learning_rate": 2.2744732542026348e-05,
      "loss": 1.269,
      "step": 3930
    },
    {
      "epoch": 1.576,
      "grad_norm": 1.0751683712005615,
      "learning_rate": 2.2339230021121725e-05,
      "loss": 1.3976,
      "step": 3940
    },
    {
      "epoch": 1.58,
      "grad_norm": 5.112256050109863,
      "learning_rate": 2.1936919830294467e-05,
      "loss": 1.6765,
      "step": 3950
    },
    {
      "epoch": 1.584,
      "grad_norm": 3.0219483375549316,
      "learning_rate": 2.153781850694082e-05,
      "loss": 1.3058,
      "step": 3960
    },
    {
      "epoch": 1.588,
      "grad_norm": 0.5735954642295837,
      "learning_rate": 2.1141942456552998e-05,
      "loss": 1.1989,
      "step": 3970
    },
    {
      "epoch": 1.592,
      "grad_norm": 3.9816439151763916,
      "learning_rate": 2.0749307952044918e-05,
      "loss": 1.3289,
      "step": 3980
    },
    {
      "epoch": 1.596,
      "grad_norm": 1.1907767057418823,
      "learning_rate": 2.0359931133083187e-05,
      "loss": 1.296,
      "step": 3990
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.8836289644241333,
      "learning_rate": 1.9973828005423757e-05,
      "loss": 1.1522,
      "step": 4000
    },
    {
      "epoch": 1.604,
      "grad_norm": 1.3064653873443604,
      "learning_rate": 1.959101444025395e-05,
      "loss": 1.2426,
      "step": 4010
    },
    {
      "epoch": 1.608,
      "grad_norm": 2.7586724758148193,
      "learning_rate": 1.921150617354006e-05,
      "loss": 1.2727,
      "step": 4020
    },
    {
      "epoch": 1.612,
      "grad_norm": 1.1080148220062256,
      "learning_rate": 1.8835318805380507e-05,
      "loss": 1.452,
      "step": 4030
    },
    {
      "epoch": 1.616,
      "grad_norm": 1.0947850942611694,
      "learning_rate": 1.8462467799364526e-05,
      "loss": 1.3786,
      "step": 4040
    },
    {
      "epoch": 1.62,
      "grad_norm": 2.0185420513153076,
      "learning_rate": 1.8092968481936634e-05,
      "loss": 1.2592,
      "step": 4050
    },
    {
      "epoch": 1.624,
      "grad_norm": 1.4310377836227417,
      "learning_rate": 1.772683604176656e-05,
      "loss": 1.3539,
      "step": 4060
    },
    {
      "epoch": 1.6280000000000001,
      "grad_norm": 5.2268195152282715,
      "learning_rate": 1.7364085529124864e-05,
      "loss": 1.314,
      "step": 4070
    },
    {
      "epoch": 1.6320000000000001,
      "grad_norm": 1.5280544757843018,
      "learning_rate": 1.7004731855264354e-05,
      "loss": 1.1943,
      "step": 4080
    },
    {
      "epoch": 1.6360000000000001,
      "grad_norm": 4.474483013153076,
      "learning_rate": 1.6648789791807018e-05,
      "loss": 1.4665,
      "step": 4090
    },
    {
      "epoch": 1.6400000000000001,
      "grad_norm": 1.230301856994629,
      "learning_rate": 1.6296273970136977e-05,
      "loss": 1.1091,
      "step": 4100
    },
    {
      "epoch": 1.6440000000000001,
      "grad_norm": 1.9440995454788208,
      "learning_rate": 1.5947198880798953e-05,
      "loss": 1.4883,
      "step": 4110
    },
    {
      "epoch": 1.6480000000000001,
      "grad_norm": 4.70466947555542,
      "learning_rate": 1.5601578872902634e-05,
      "loss": 1.0545,
      "step": 4120
    },
    {
      "epoch": 1.6520000000000001,
      "grad_norm": 0.6586902141571045,
      "learning_rate": 1.525942815353284e-05,
      "loss": 1.3381,
      "step": 4130
    },
    {
      "epoch": 1.6560000000000001,
      "grad_norm": 2.4789748191833496,
      "learning_rate": 1.4920760787165545e-05,
      "loss": 0.9666,
      "step": 4140
    },
    {
      "epoch": 1.6600000000000001,
      "grad_norm": 2.134690999984741,
      "learning_rate": 1.4585590695089701e-05,
      "loss": 1.4263,
      "step": 4150
    },
    {
      "epoch": 1.6640000000000001,
      "grad_norm": 3.0671825408935547,
      "learning_rate": 1.4253931654835018e-05,
      "loss": 1.1569,
      "step": 4160
    },
    {
      "epoch": 1.6680000000000001,
      "grad_norm": 3.4060544967651367,
      "learning_rate": 1.3925797299605647e-05,
      "loss": 1.3841,
      "step": 4170
    },
    {
      "epoch": 1.6720000000000002,
      "grad_norm": 2.5917115211486816,
      "learning_rate": 1.3601201117719676e-05,
      "loss": 1.5013,
      "step": 4180
    },
    {
      "epoch": 1.6760000000000002,
      "grad_norm": 7.282817840576172,
      "learning_rate": 1.3280156452054804e-05,
      "loss": 1.4402,
      "step": 4190
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 5.3692522048950195,
      "learning_rate": 1.2962676499499793e-05,
      "loss": 1.498,
      "step": 4200
    },
    {
      "epoch": 1.6840000000000002,
      "grad_norm": 0.5932410955429077,
      "learning_rate": 1.2648774310412038e-05,
      "loss": 1.2068,
      "step": 4210
    },
    {
      "epoch": 1.688,
      "grad_norm": 1.618551254272461,
      "learning_rate": 1.2338462788081006e-05,
      "loss": 1.2134,
      "step": 4220
    },
    {
      "epoch": 1.692,
      "grad_norm": 1.317176342010498,
      "learning_rate": 1.2031754688197994e-05,
      "loss": 1.195,
      "step": 4230
    },
    {
      "epoch": 1.696,
      "grad_norm": 1.8996350765228271,
      "learning_rate": 1.1728662618331698e-05,
      "loss": 1.2446,
      "step": 4240
    },
    {
      "epoch": 1.7,
      "grad_norm": 1.4385831356048584,
      "learning_rate": 1.1429199037409987e-05,
      "loss": 1.3435,
      "step": 4250
    },
    {
      "epoch": 1.704,
      "grad_norm": 0.7144060134887695,
      "learning_rate": 1.1133376255207751e-05,
      "loss": 1.2434,
      "step": 4260
    },
    {
      "epoch": 1.708,
      "grad_norm": 0.6822806000709534,
      "learning_rate": 1.08412064318409e-05,
      "loss": 1.1168,
      "step": 4270
    },
    {
      "epoch": 1.712,
      "grad_norm": 2.531416416168213,
      "learning_rate": 1.0552701577266532e-05,
      "loss": 1.5503,
      "step": 4280
    },
    {
      "epoch": 1.716,
      "grad_norm": 1.4844268560409546,
      "learning_rate": 1.0267873550789208e-05,
      "loss": 1.2382,
      "step": 4290
    },
    {
      "epoch": 1.72,
      "grad_norm": 2.5253801345825195,
      "learning_rate": 9.986734060573544e-06,
      "loss": 1.4586,
      "step": 4300
    },
    {
      "epoch": 1.724,
      "grad_norm": 1.3339935541152954,
      "learning_rate": 9.709294663162771e-06,
      "loss": 1.1279,
      "step": 4310
    },
    {
      "epoch": 1.728,
      "grad_norm": 0.8036783337593079,
      "learning_rate": 9.43556676300389e-06,
      "loss": 1.2094,
      "step": 4320
    },
    {
      "epoch": 1.732,
      "grad_norm": 0.9961788058280945,
      "learning_rate": 9.165561611978767e-06,
      "loss": 1.3781,
      "step": 4330
    },
    {
      "epoch": 1.736,
      "grad_norm": 1.6110302209854126,
      "learning_rate": 8.89929030894161e-06,
      "loss": 1.0644,
      "step": 4340
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.6981638669967651,
      "learning_rate": 8.636763799262793e-06,
      "loss": 0.9935,
      "step": 4350
    },
    {
      "epoch": 1.744,
      "grad_norm": 1.2562626600265503,
      "learning_rate": 8.377992874378848e-06,
      "loss": 1.2807,
      "step": 4360
    },
    {
      "epoch": 1.748,
      "grad_norm": 1.2129998207092285,
      "learning_rate": 8.122988171348989e-06,
      "loss": 1.406,
      "step": 4370
    },
    {
      "epoch": 1.752,
      "grad_norm": 1.5875440835952759,
      "learning_rate": 7.871760172417763e-06,
      "loss": 1.3066,
      "step": 4380
    },
    {
      "epoch": 1.756,
      "grad_norm": 1.2498646974563599,
      "learning_rate": 7.624319204584207e-06,
      "loss": 1.2516,
      "step": 4390
    },
    {
      "epoch": 1.76,
      "grad_norm": 1.9271297454833984,
      "learning_rate": 7.380675439177364e-06,
      "loss": 1.1751,
      "step": 4400
    },
    {
      "epoch": 1.764,
      "grad_norm": 1.6404473781585693,
      "learning_rate": 7.140838891438129e-06,
      "loss": 1.2061,
      "step": 4410
    },
    {
      "epoch": 1.768,
      "grad_norm": 1.033085823059082,
      "learning_rate": 6.904819420107611e-06,
      "loss": 1.1706,
      "step": 4420
    },
    {
      "epoch": 1.772,
      "grad_norm": 0.7338146567344666,
      "learning_rate": 6.672626727021847e-06,
      "loss": 1.2553,
      "step": 4430
    },
    {
      "epoch": 1.776,
      "grad_norm": 0.8123170137405396,
      "learning_rate": 6.444270356713034e-06,
      "loss": 1.2211,
      "step": 4440
    },
    {
      "epoch": 1.78,
      "grad_norm": 1.9350513219833374,
      "learning_rate": 6.219759696017113e-06,
      "loss": 1.4738,
      "step": 4450
    },
    {
      "epoch": 1.784,
      "grad_norm": 11.092470169067383,
      "learning_rate": 5.999103973688003e-06,
      "loss": 1.3764,
      "step": 4460
    },
    {
      "epoch": 1.788,
      "grad_norm": 1.0213615894317627,
      "learning_rate": 5.7823122600182185e-06,
      "loss": 1.1436,
      "step": 4470
    },
    {
      "epoch": 1.792,
      "grad_norm": 0.8807603120803833,
      "learning_rate": 5.569393466465978e-06,
      "loss": 1.3687,
      "step": 4480
    },
    {
      "epoch": 1.796,
      "grad_norm": 1.154183268547058,
      "learning_rate": 5.3603563452889525e-06,
      "loss": 1.3174,
      "step": 4490
    },
    {
      "epoch": 1.8,
      "grad_norm": 1.8064628839492798,
      "learning_rate": 5.1552094891844315e-06,
      "loss": 1.0644,
      "step": 4500
    }
  ],
  "logging_steps": 10,
  "max_steps": 5000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 9.5128413160661e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
