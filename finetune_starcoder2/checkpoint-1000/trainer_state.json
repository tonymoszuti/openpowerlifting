{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.4,
  "eval_steps": 500,
  "global_step": 1000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.004,
      "grad_norm": 0.3426077663898468,
      "learning_rate": 2e-05,
      "loss": 2.9314,
      "step": 10
    },
    {
      "epoch": 0.008,
      "grad_norm": 0.5724144577980042,
      "learning_rate": 4e-05,
      "loss": 2.8247,
      "step": 20
    },
    {
      "epoch": 0.012,
      "grad_norm": 0.7688854336738586,
      "learning_rate": 6e-05,
      "loss": 2.5122,
      "step": 30
    },
    {
      "epoch": 0.016,
      "grad_norm": 0.8625675439834595,
      "learning_rate": 8e-05,
      "loss": 2.7368,
      "step": 40
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.1354831457138062,
      "learning_rate": 0.0001,
      "loss": 2.3019,
      "step": 50
    },
    {
      "epoch": 0.024,
      "grad_norm": 3.378488540649414,
      "learning_rate": 0.00012,
      "loss": 2.3206,
      "step": 60
    },
    {
      "epoch": 0.028,
      "grad_norm": 1.3570775985717773,
      "learning_rate": 0.00014,
      "loss": 2.0744,
      "step": 70
    },
    {
      "epoch": 0.032,
      "grad_norm": NaN,
      "learning_rate": 0.00015800000000000002,
      "loss": 1.8436,
      "step": 80
    },
    {
      "epoch": 0.036,
      "grad_norm": 4.027080535888672,
      "learning_rate": 0.00017800000000000002,
      "loss": 2.3957,
      "step": 90
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.2452301979064941,
      "learning_rate": 0.00019800000000000002,
      "loss": 2.1942,
      "step": 100
    },
    {
      "epoch": 0.044,
      "grad_norm": 4.084047317504883,
      "learning_rate": 0.0001999983352025441,
      "loss": 1.8502,
      "step": 110
    },
    {
      "epoch": 0.048,
      "grad_norm": 2.900085210800171,
      "learning_rate": 0.00019999258041830607,
      "loss": 1.8054,
      "step": 120
    },
    {
      "epoch": 0.052,
      "grad_norm": 3.3914549350738525,
      "learning_rate": 0.0001999827153307312,
      "loss": 1.9059,
      "step": 130
    },
    {
      "epoch": 0.056,
      "grad_norm": 2.0497732162475586,
      "learning_rate": 0.00019996874034533462,
      "loss": 1.496,
      "step": 140
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.8106114864349365,
      "learning_rate": 0.00019995065603657316,
      "loss": 2.0725,
      "step": 150
    },
    {
      "epoch": 0.064,
      "grad_norm": 1.7514961957931519,
      "learning_rate": 0.000199928463147822,
      "loss": 1.9731,
      "step": 160
    },
    {
      "epoch": 0.068,
      "grad_norm": 3.570523262023926,
      "learning_rate": 0.00019990216259134386,
      "loss": 1.6582,
      "step": 170
    },
    {
      "epoch": 0.072,
      "grad_norm": 1.4778298139572144,
      "learning_rate": 0.0001998717554482516,
      "loss": 2.0631,
      "step": 180
    },
    {
      "epoch": 0.076,
      "grad_norm": 4.078042507171631,
      "learning_rate": 0.00019983724296846375,
      "loss": 1.6277,
      "step": 190
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.9864320755004883,
      "learning_rate": 0.00019979862657065324,
      "loss": 1.8355,
      "step": 200
    },
    {
      "epoch": 0.084,
      "grad_norm": 2.8769729137420654,
      "learning_rate": 0.00019975590784218888,
      "loss": 1.9431,
      "step": 210
    },
    {
      "epoch": 0.088,
      "grad_norm": 4.924728870391846,
      "learning_rate": 0.00019970908853907026,
      "loss": 1.7316,
      "step": 220
    },
    {
      "epoch": 0.092,
      "grad_norm": 1.9807220697402954,
      "learning_rate": 0.00019965817058585563,
      "loss": 1.7061,
      "step": 230
    },
    {
      "epoch": 0.096,
      "grad_norm": 3.0840351581573486,
      "learning_rate": 0.00019960315607558255,
      "loss": 1.7857,
      "step": 240
    },
    {
      "epoch": 0.1,
      "grad_norm": 3.5300915241241455,
      "learning_rate": 0.0001995440472696821,
      "loss": 1.6178,
      "step": 250
    },
    {
      "epoch": 0.104,
      "grad_norm": 1.3585745096206665,
      "learning_rate": 0.00019948084659788574,
      "loss": 1.4387,
      "step": 260
    },
    {
      "epoch": 0.108,
      "grad_norm": 6.052093029022217,
      "learning_rate": 0.00019941355665812558,
      "loss": 1.8342,
      "step": 270
    },
    {
      "epoch": 0.112,
      "grad_norm": 1.362105131149292,
      "learning_rate": 0.00019934218021642748,
      "loss": 1.9202,
      "step": 280
    },
    {
      "epoch": 0.116,
      "grad_norm": 3.1927781105041504,
      "learning_rate": 0.00019926672020679736,
      "loss": 1.633,
      "step": 290
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.9030426740646362,
      "learning_rate": 0.00019918717973110072,
      "loss": 2.0792,
      "step": 300
    },
    {
      "epoch": 0.124,
      "grad_norm": 1.5642791986465454,
      "learning_rate": 0.0001991035620589349,
      "loss": 1.5047,
      "step": 310
    },
    {
      "epoch": 0.128,
      "grad_norm": 2.054460048675537,
      "learning_rate": 0.000199015870627495,
      "loss": 1.6355,
      "step": 320
    },
    {
      "epoch": 0.132,
      "grad_norm": 2.1825244426727295,
      "learning_rate": 0.00019892410904143222,
      "loss": 1.5409,
      "step": 330
    },
    {
      "epoch": 0.136,
      "grad_norm": 1.5228831768035889,
      "learning_rate": 0.00019882828107270598,
      "loss": 1.8481,
      "step": 340
    },
    {
      "epoch": 0.14,
      "grad_norm": 5.09263801574707,
      "learning_rate": 0.00019872839066042874,
      "loss": 1.7745,
      "step": 350
    },
    {
      "epoch": 0.144,
      "grad_norm": 3.2239630222320557,
      "learning_rate": 0.00019862444191070408,
      "loss": 1.6073,
      "step": 360
    },
    {
      "epoch": 0.148,
      "grad_norm": 1.4044709205627441,
      "learning_rate": 0.00019851643909645804,
      "loss": 1.5039,
      "step": 370
    },
    {
      "epoch": 0.152,
      "grad_norm": 3.51741623878479,
      "learning_rate": 0.0001984043866572632,
      "loss": 1.6572,
      "step": 380
    },
    {
      "epoch": 0.156,
      "grad_norm": 0.8841949105262756,
      "learning_rate": 0.0001982882891991565,
      "loss": 1.6853,
      "step": 390
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.8144136667251587,
      "learning_rate": 0.00019816815149444977,
      "loss": 1.5475,
      "step": 400
    },
    {
      "epoch": 0.164,
      "grad_norm": 0.8289576768875122,
      "learning_rate": 0.00019804397848153342,
      "loss": 1.5933,
      "step": 410
    },
    {
      "epoch": 0.168,
      "grad_norm": 0.7508878111839294,
      "learning_rate": 0.0001979157752646737,
      "loss": 1.3729,
      "step": 420
    },
    {
      "epoch": 0.172,
      "grad_norm": 2.1276731491088867,
      "learning_rate": 0.0001977835471138027,
      "loss": 1.536,
      "step": 430
    },
    {
      "epoch": 0.176,
      "grad_norm": 1.8165258169174194,
      "learning_rate": 0.00019764729946430184,
      "loss": 1.7872,
      "step": 440
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.383781909942627,
      "learning_rate": 0.00019750703791677828,
      "loss": 1.4654,
      "step": 450
    },
    {
      "epoch": 0.184,
      "grad_norm": 5.184279918670654,
      "learning_rate": 0.0001973627682368349,
      "loss": 1.4823,
      "step": 460
    },
    {
      "epoch": 0.188,
      "grad_norm": 2.337721109390259,
      "learning_rate": 0.0001972144963548332,
      "loss": 1.64,
      "step": 470
    },
    {
      "epoch": 0.192,
      "grad_norm": 1.0584999322891235,
      "learning_rate": 0.00019706222836564952,
      "loss": 1.4945,
      "step": 480
    },
    {
      "epoch": 0.196,
      "grad_norm": 2.0738327503204346,
      "learning_rate": 0.00019690597052842446,
      "loss": 1.5313,
      "step": 490
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.115068197250366,
      "learning_rate": 0.00019674572926630567,
      "loss": 1.6322,
      "step": 500
    },
    {
      "epoch": 0.204,
      "grad_norm": 1.3315216302871704,
      "learning_rate": 0.00019658151116618385,
      "loss": 1.5415,
      "step": 510
    },
    {
      "epoch": 0.208,
      "grad_norm": 1.3839948177337646,
      "learning_rate": 0.0001964133229784219,
      "loss": 1.435,
      "step": 520
    },
    {
      "epoch": 0.212,
      "grad_norm": 5.277719974517822,
      "learning_rate": 0.00019624117161657752,
      "loss": 1.5693,
      "step": 530
    },
    {
      "epoch": 0.216,
      "grad_norm": 1.7046406269073486,
      "learning_rate": 0.00019606506415711881,
      "loss": 1.7607,
      "step": 540
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.4589056968688965,
      "learning_rate": 0.00019588500783913375,
      "loss": 1.4566,
      "step": 550
    },
    {
      "epoch": 0.224,
      "grad_norm": 3.3946352005004883,
      "learning_rate": 0.00019570101006403226,
      "loss": 1.4359,
      "step": 560
    },
    {
      "epoch": 0.228,
      "grad_norm": 1.8414881229400635,
      "learning_rate": 0.0001955130783952423,
      "loss": 1.4338,
      "step": 570
    },
    {
      "epoch": 0.232,
      "grad_norm": 0.9358095526695251,
      "learning_rate": 0.00019532122055789864,
      "loss": 1.2068,
      "step": 580
    },
    {
      "epoch": 0.236,
      "grad_norm": 1.4463573694229126,
      "learning_rate": 0.00019512544443852557,
      "loss": 1.3874,
      "step": 590
    },
    {
      "epoch": 0.24,
      "grad_norm": 3.279111385345459,
      "learning_rate": 0.00019492575808471247,
      "loss": 1.7293,
      "step": 600
    },
    {
      "epoch": 0.244,
      "grad_norm": 1.105846881866455,
      "learning_rate": 0.00019472216970478328,
      "loss": 1.3392,
      "step": 610
    },
    {
      "epoch": 0.248,
      "grad_norm": 1.1813045740127563,
      "learning_rate": 0.0001945146876674589,
      "loss": 1.3584,
      "step": 620
    },
    {
      "epoch": 0.252,
      "grad_norm": 4.897843837738037,
      "learning_rate": 0.00019430332050151324,
      "loss": 1.6823,
      "step": 630
    },
    {
      "epoch": 0.256,
      "grad_norm": 2.2838189601898193,
      "learning_rate": 0.00019408807689542257,
      "loss": 1.509,
      "step": 640
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.1784093379974365,
      "learning_rate": 0.00019386896569700853,
      "loss": 1.3766,
      "step": 650
    },
    {
      "epoch": 0.264,
      "grad_norm": 0.8633360266685486,
      "learning_rate": 0.00019364599591307425,
      "loss": 1.4166,
      "step": 660
    },
    {
      "epoch": 0.268,
      "grad_norm": 0.9131094217300415,
      "learning_rate": 0.0001934191767090343,
      "loss": 1.2089,
      "step": 670
    },
    {
      "epoch": 0.272,
      "grad_norm": 1.5715149641036987,
      "learning_rate": 0.0001931885174085377,
      "loss": 1.7495,
      "step": 680
    },
    {
      "epoch": 0.276,
      "grad_norm": 0.6264223456382751,
      "learning_rate": 0.00019295402749308497,
      "loss": 1.7577,
      "step": 690
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.2082910537719727,
      "learning_rate": 0.00019271571660163793,
      "loss": 1.5309,
      "step": 700
    },
    {
      "epoch": 0.284,
      "grad_norm": 3.826303005218506,
      "learning_rate": 0.00019247359453022407,
      "loss": 1.5806,
      "step": 710
    },
    {
      "epoch": 0.288,
      "grad_norm": 0.7209219336509705,
      "learning_rate": 0.00019222767123153336,
      "loss": 1.4271,
      "step": 720
    },
    {
      "epoch": 0.292,
      "grad_norm": 2.2184195518493652,
      "learning_rate": 0.00019197795681450937,
      "loss": 1.452,
      "step": 730
    },
    {
      "epoch": 0.296,
      "grad_norm": 1.07893705368042,
      "learning_rate": 0.0001917244615439338,
      "loss": 1.433,
      "step": 740
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.4187618494033813,
      "learning_rate": 0.00019146719584000428,
      "loss": 1.3766,
      "step": 750
    },
    {
      "epoch": 0.304,
      "grad_norm": 2.4059064388275146,
      "learning_rate": 0.0001912061702779063,
      "loss": 1.6586,
      "step": 760
    },
    {
      "epoch": 0.308,
      "grad_norm": 1.0006306171417236,
      "learning_rate": 0.0001909413955873783,
      "loss": 1.5635,
      "step": 770
    },
    {
      "epoch": 0.312,
      "grad_norm": 1.299811601638794,
      "learning_rate": 0.00019067288265227082,
      "loss": 1.5299,
      "step": 780
    },
    {
      "epoch": 0.316,
      "grad_norm": 0.9722449779510498,
      "learning_rate": 0.00019040064251009886,
      "loss": 1.2976,
      "step": 790
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.4584935903549194,
      "learning_rate": 0.00019012468635158845,
      "loss": 1.7872,
      "step": 800
    },
    {
      "epoch": 0.324,
      "grad_norm": 2.7648754119873047,
      "learning_rate": 0.00018984502552021635,
      "loss": 1.584,
      "step": 810
    },
    {
      "epoch": 0.328,
      "grad_norm": 1.7412203550338745,
      "learning_rate": 0.000189561671511744,
      "loss": 1.5812,
      "step": 820
    },
    {
      "epoch": 0.332,
      "grad_norm": 1.3458647727966309,
      "learning_rate": 0.0001892746359737449,
      "loss": 1.6313,
      "step": 830
    },
    {
      "epoch": 0.336,
      "grad_norm": 1.460942268371582,
      "learning_rate": 0.00018898393070512572,
      "loss": 1.5319,
      "step": 840
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.9537712335586548,
      "learning_rate": 0.0001886895676556415,
      "loss": 1.52,
      "step": 850
    },
    {
      "epoch": 0.344,
      "grad_norm": 2.171046257019043,
      "learning_rate": 0.00018839155892540424,
      "loss": 1.5534,
      "step": 860
    },
    {
      "epoch": 0.348,
      "grad_norm": 0.891879141330719,
      "learning_rate": 0.0001880899167643856,
      "loss": 1.3827,
      "step": 870
    },
    {
      "epoch": 0.352,
      "grad_norm": 3.126929521560669,
      "learning_rate": 0.0001877846535719134,
      "loss": 1.618,
      "step": 880
    },
    {
      "epoch": 0.356,
      "grad_norm": 2.0574615001678467,
      "learning_rate": 0.0001874757818961618,
      "loss": 1.6419,
      "step": 890
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.8916999101638794,
      "learning_rate": 0.00018716331443363563,
      "loss": 1.3158,
      "step": 900
    },
    {
      "epoch": 0.364,
      "grad_norm": 0.4915868639945984,
      "learning_rate": 0.0001868472640286485,
      "loss": 1.276,
      "step": 910
    },
    {
      "epoch": 0.368,
      "grad_norm": 7.387997150421143,
      "learning_rate": 0.00018652764367279461,
      "loss": 1.6373,
      "step": 920
    },
    {
      "epoch": 0.372,
      "grad_norm": 2.565603733062744,
      "learning_rate": 0.0001862044665044149,
      "loss": 1.6126,
      "step": 930
    },
    {
      "epoch": 0.376,
      "grad_norm": 1.8439942598342896,
      "learning_rate": 0.00018587774580805703,
      "loss": 1.4384,
      "step": 940
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.3556010723114014,
      "learning_rate": 0.0001855474950139291,
      "loss": 1.3861,
      "step": 950
    },
    {
      "epoch": 0.384,
      "grad_norm": 3.6868979930877686,
      "learning_rate": 0.00018521372769734774,
      "loss": 1.4213,
      "step": 960
    },
    {
      "epoch": 0.388,
      "grad_norm": 2.39813232421875,
      "learning_rate": 0.00018487645757818015,
      "loss": 1.486,
      "step": 970
    },
    {
      "epoch": 0.392,
      "grad_norm": 0.8430299758911133,
      "learning_rate": 0.0001845356985202798,
      "loss": 1.4516,
      "step": 980
    },
    {
      "epoch": 0.396,
      "grad_norm": 1.346730351448059,
      "learning_rate": 0.00018419146453091701,
      "loss": 1.4761,
      "step": 990
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.6636066436767578,
      "learning_rate": 0.00018384376976020276,
      "loss": 1.4382,
      "step": 1000
    }
  ],
  "logging_steps": 10,
  "max_steps": 5000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.101007655639245e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
