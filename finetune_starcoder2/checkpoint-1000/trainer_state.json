{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.4,
  "eval_steps": 500,
  "global_step": 1000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.004,
      "grad_norm": 0.342077374458313,
      "learning_rate": 2e-05,
      "loss": 2.9316,
      "step": 10
    },
    {
      "epoch": 0.008,
      "grad_norm": 0.5726203918457031,
      "learning_rate": 4e-05,
      "loss": 2.8248,
      "step": 20
    },
    {
      "epoch": 0.012,
      "grad_norm": 0.766245424747467,
      "learning_rate": 6e-05,
      "loss": 2.5121,
      "step": 30
    },
    {
      "epoch": 0.016,
      "grad_norm": 0.8620803952217102,
      "learning_rate": 8e-05,
      "loss": 2.7369,
      "step": 40
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.1365962028503418,
      "learning_rate": 0.0001,
      "loss": 2.3017,
      "step": 50
    },
    {
      "epoch": 0.024,
      "grad_norm": 3.229485511779785,
      "learning_rate": 0.00012,
      "loss": 2.32,
      "step": 60
    },
    {
      "epoch": 0.028,
      "grad_norm": 1.3540401458740234,
      "learning_rate": 0.00014,
      "loss": 2.0739,
      "step": 70
    },
    {
      "epoch": 0.032,
      "grad_norm": 10.885794639587402,
      "learning_rate": 0.00016,
      "loss": 1.8389,
      "step": 80
    },
    {
      "epoch": 0.036,
      "grad_norm": 4.126986980438232,
      "learning_rate": 0.00018,
      "loss": 2.3826,
      "step": 90
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.2451304197311401,
      "learning_rate": 0.0002,
      "loss": 2.1889,
      "step": 100
    },
    {
      "epoch": 0.044,
      "grad_norm": 3.977038621902466,
      "learning_rate": 0.0001999390827019096,
      "loss": 1.8484,
      "step": 110
    },
    {
      "epoch": 0.048,
      "grad_norm": 3.180800437927246,
      "learning_rate": 0.00019975640502598244,
      "loss": 1.8096,
      "step": 120
    },
    {
      "epoch": 0.052,
      "grad_norm": 2.0270326137542725,
      "learning_rate": 0.00019945218953682734,
      "loss": 1.8999,
      "step": 130
    },
    {
      "epoch": 0.056,
      "grad_norm": 2.152052402496338,
      "learning_rate": 0.00019902680687415705,
      "loss": 1.4774,
      "step": 140
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.9559067487716675,
      "learning_rate": 0.00019848077530122083,
      "loss": 2.0366,
      "step": 150
    },
    {
      "epoch": 0.064,
      "grad_norm": 1.7231287956237793,
      "learning_rate": 0.00019781476007338058,
      "loss": 1.9729,
      "step": 160
    },
    {
      "epoch": 0.068,
      "grad_norm": 3.862616777420044,
      "learning_rate": 0.00019702957262759965,
      "loss": 1.6547,
      "step": 170
    },
    {
      "epoch": 0.072,
      "grad_norm": 1.4463926553726196,
      "learning_rate": 0.0001961261695938319,
      "loss": 2.0474,
      "step": 180
    },
    {
      "epoch": 0.076,
      "grad_norm": 3.0437774658203125,
      "learning_rate": 0.00019510565162951537,
      "loss": 1.629,
      "step": 190
    },
    {
      "epoch": 0.08,
      "grad_norm": 5.21061372756958,
      "learning_rate": 0.00019396926207859084,
      "loss": 1.8619,
      "step": 200
    },
    {
      "epoch": 0.084,
      "grad_norm": 2.355529308319092,
      "learning_rate": 0.00019284858268809137,
      "loss": 1.9568,
      "step": 210
    },
    {
      "epoch": 0.088,
      "grad_norm": 4.419785976409912,
      "learning_rate": 0.0001914959667849825,
      "loss": 1.732,
      "step": 220
    },
    {
      "epoch": 0.092,
      "grad_norm": 2.1426680088043213,
      "learning_rate": 0.00019003187714021938,
      "loss": 1.7065,
      "step": 230
    },
    {
      "epoch": 0.096,
      "grad_norm": 4.890607833862305,
      "learning_rate": 0.0001884580975215084,
      "loss": 1.7711,
      "step": 240
    },
    {
      "epoch": 0.1,
      "grad_norm": 3.177260160446167,
      "learning_rate": 0.00018677654533689287,
      "loss": 1.6181,
      "step": 250
    },
    {
      "epoch": 0.104,
      "grad_norm": 1.2959585189819336,
      "learning_rate": 0.00018498926929868642,
      "loss": 1.4323,
      "step": 260
    },
    {
      "epoch": 0.108,
      "grad_norm": 6.1781511306762695,
      "learning_rate": 0.00018309844692743283,
      "loss": 1.8324,
      "step": 270
    },
    {
      "epoch": 0.112,
      "grad_norm": 1.5312156677246094,
      "learning_rate": 0.00018110638189893267,
      "loss": 1.9086,
      "step": 280
    },
    {
      "epoch": 0.116,
      "grad_norm": 11.437456130981445,
      "learning_rate": 0.00017901550123756906,
      "loss": 1.6075,
      "step": 290
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.2327284812927246,
      "learning_rate": 0.00017705132427757895,
      "loss": 2.1101,
      "step": 300
    },
    {
      "epoch": 0.124,
      "grad_norm": 1.5498087406158447,
      "learning_rate": 0.0001747798090498532,
      "loss": 1.5224,
      "step": 310
    },
    {
      "epoch": 0.128,
      "grad_norm": 2.1788697242736816,
      "learning_rate": 0.00017241718614374678,
      "loss": 1.6521,
      "step": 320
    },
    {
      "epoch": 0.132,
      "grad_norm": 2.300511598587036,
      "learning_rate": 0.00016996633405133655,
      "loss": 1.5521,
      "step": 330
    },
    {
      "epoch": 0.136,
      "grad_norm": 1.8573663234710693,
      "learning_rate": 0.00016743023875837233,
      "loss": 1.8697,
      "step": 340
    },
    {
      "epoch": 0.14,
      "grad_norm": 4.041130542755127,
      "learning_rate": 0.0001648119901063131,
      "loss": 1.7989,
      "step": 350
    },
    {
      "epoch": 0.144,
      "grad_norm": 4.511508464813232,
      "learning_rate": 0.00016211477802783103,
      "loss": 1.6115,
      "step": 360
    },
    {
      "epoch": 0.148,
      "grad_norm": 2.5353140830993652,
      "learning_rate": 0.00015934188866037016,
      "loss": 1.507,
      "step": 370
    },
    {
      "epoch": 0.152,
      "grad_norm": 3.6142191886901855,
      "learning_rate": 0.0001564967003424938,
      "loss": 1.6684,
      "step": 380
    },
    {
      "epoch": 0.156,
      "grad_norm": 1.0525554418563843,
      "learning_rate": 0.00015358267949789966,
      "loss": 1.7005,
      "step": 390
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.8724220991134644,
      "learning_rate": 0.00015060337641211637,
      "loss": 1.5617,
      "step": 400
    },
    {
      "epoch": 0.164,
      "grad_norm": 0.8610819578170776,
      "learning_rate": 0.00014756242090702756,
      "loss": 1.6122,
      "step": 410
    },
    {
      "epoch": 0.168,
      "grad_norm": 0.615998387336731,
      "learning_rate": 0.00014446351791849276,
      "loss": 1.3908,
      "step": 420
    },
    {
      "epoch": 0.172,
      "grad_norm": 3.264197587966919,
      "learning_rate": 0.0001413104429824542,
      "loss": 1.5529,
      "step": 430
    },
    {
      "epoch": 0.176,
      "grad_norm": 1.7337230443954468,
      "learning_rate": 0.00013810703763502744,
      "loss": 1.8179,
      "step": 440
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.548945188522339,
      "learning_rate": 0.00013485720473218154,
      "loss": 1.4755,
      "step": 450
    },
    {
      "epoch": 0.184,
      "grad_norm": 5.8239426612854,
      "learning_rate": 0.00013156490369471027,
      "loss": 1.4946,
      "step": 460
    },
    {
      "epoch": 0.188,
      "grad_norm": 13.746667861938477,
      "learning_rate": 0.00012823414568428768,
      "loss": 1.66,
      "step": 470
    },
    {
      "epoch": 0.192,
      "grad_norm": 1.5562952756881714,
      "learning_rate": 0.0001248689887164855,
      "loss": 1.5043,
      "step": 480
    },
    {
      "epoch": 0.196,
      "grad_norm": 2.276383876800537,
      "learning_rate": 0.00012147353271670634,
      "loss": 1.5648,
      "step": 490
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.326223611831665,
      "learning_rate": 0.00011805191452505602,
      "loss": 1.6495,
      "step": 500
    },
    {
      "epoch": 0.204,
      "grad_norm": 2.951719284057617,
      "learning_rate": 0.00011460830285624118,
      "loss": 1.5556,
      "step": 510
    },
    {
      "epoch": 0.208,
      "grad_norm": 1.460606336593628,
      "learning_rate": 0.00011114689322063255,
      "loss": 1.4429,
      "step": 520
    },
    {
      "epoch": 0.212,
      "grad_norm": 6.036488056182861,
      "learning_rate": 0.00010767190281268187,
      "loss": 1.593,
      "step": 530
    },
    {
      "epoch": 0.216,
      "grad_norm": 1.8863462209701538,
      "learning_rate": 0.00010418756537291996,
      "loss": 1.7732,
      "step": 540
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.8150880336761475,
      "learning_rate": 0.00010069812602979615,
      "loss": 1.4762,
      "step": 550
    },
    {
      "epoch": 0.224,
      "grad_norm": 3.55130672454834,
      "learning_rate": 9.720783612764314e-05,
      "loss": 1.4516,
      "step": 560
    },
    {
      "epoch": 0.228,
      "grad_norm": 2.7150626182556152,
      "learning_rate": 9.372094804706867e-05,
      "loss": 1.4542,
      "step": 570
    },
    {
      "epoch": 0.232,
      "grad_norm": 0.9170523881912231,
      "learning_rate": 9.024171002408506e-05,
      "loss": 1.2161,
      "step": 580
    },
    {
      "epoch": 0.236,
      "grad_norm": 1.3619346618652344,
      "learning_rate": 8.677436097428775e-05,
      "loss": 1.3958,
      "step": 590
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.9170267581939697,
      "learning_rate": 8.332312532838978e-05,
      "loss": 1.7389,
      "step": 600
    },
    {
      "epoch": 0.244,
      "grad_norm": 1.1801549196243286,
      "learning_rate": 7.989220788540355e-05,
      "loss": 1.3487,
      "step": 610
    },
    {
      "epoch": 0.248,
      "grad_norm": 1.7522637844085693,
      "learning_rate": 7.6485788689741e-05,
      "loss": 1.3719,
      "step": 620
    },
    {
      "epoch": 0.252,
      "grad_norm": 4.972155570983887,
      "learning_rate": 7.310801793847344e-05,
      "loss": 1.6931,
      "step": 630
    },
    {
      "epoch": 0.256,
      "grad_norm": 2.6281981468200684,
      "learning_rate": 6.976301092495556e-05,
      "loss": 1.5321,
      "step": 640
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.618680000305176,
      "learning_rate": 6.64548430249745e-05,
      "loss": 1.3878,
      "step": 650
    },
    {
      "epoch": 0.264,
      "grad_norm": 1.1701055765151978,
      "learning_rate": 6.318754473153221e-05,
      "loss": 1.4827,
      "step": 660
    },
    {
      "epoch": 0.268,
      "grad_norm": 1.0655996799468994,
      "learning_rate": 5.9965096744310526e-05,
      "loss": 1.2237,
      "step": 670
    },
    {
      "epoch": 0.272,
      "grad_norm": 2.2040469646453857,
      "learning_rate": 5.679142511980175e-05,
      "loss": 1.7661,
      "step": 680
    },
    {
      "epoch": 0.276,
      "grad_norm": 0.6887742877006531,
      "learning_rate": 5.3670396488013854e-05,
      "loss": 1.7807,
      "step": 690
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.08853816986084,
      "learning_rate": 5.0605813341576924e-05,
      "loss": 1.5428,
      "step": 700
    },
    {
      "epoch": 0.284,
      "grad_norm": 4.671180248260498,
      "learning_rate": 4.7601409402992106e-05,
      "loss": 1.6359,
      "step": 710
    },
    {
      "epoch": 0.288,
      "grad_norm": 0.855129599571228,
      "learning_rate": 4.46608450756656e-05,
      "loss": 1.4539,
      "step": 720
    },
    {
      "epoch": 0.292,
      "grad_norm": 2.272352457046509,
      "learning_rate": 4.1787702984271074e-05,
      "loss": 1.4659,
      "step": 730
    },
    {
      "epoch": 0.296,
      "grad_norm": 1.1527020931243896,
      "learning_rate": 3.8985483609873244e-05,
      "loss": 1.4695,
      "step": 740
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.9365367889404297,
      "learning_rate": 3.6257601025131026e-05,
      "loss": 1.415,
      "step": 750
    },
    {
      "epoch": 0.304,
      "grad_norm": 2.8121235370635986,
      "learning_rate": 3.360737873477584e-05,
      "loss": 1.7048,
      "step": 760
    },
    {
      "epoch": 0.308,
      "grad_norm": 1.578669786453247,
      "learning_rate": 3.103804562643302e-05,
      "loss": 1.6066,
      "step": 770
    },
    {
      "epoch": 0.312,
      "grad_norm": 1.3807989358901978,
      "learning_rate": 2.8552732036719687e-05,
      "loss": 1.5355,
      "step": 780
    },
    {
      "epoch": 0.316,
      "grad_norm": 1.9199265241622925,
      "learning_rate": 2.615446593741161e-05,
      "loss": 1.3203,
      "step": 790
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.8399525880813599,
      "learning_rate": 2.3846169246326343e-05,
      "loss": 1.8358,
      "step": 800
    },
    {
      "epoch": 0.324,
      "grad_norm": 3.012094497680664,
      "learning_rate": 2.163065426741603e-05,
      "loss": 1.6335,
      "step": 810
    },
    {
      "epoch": 0.328,
      "grad_norm": 2.2663190364837646,
      "learning_rate": 1.9510620264408596e-05,
      "loss": 1.5976,
      "step": 820
    },
    {
      "epoch": 0.332,
      "grad_norm": 1.6242934465408325,
      "learning_rate": 1.7488650172170496e-05,
      "loss": 1.6646,
      "step": 830
    },
    {
      "epoch": 0.336,
      "grad_norm": 2.2229416370391846,
      "learning_rate": 1.5567207449798515e-05,
      "loss": 1.5645,
      "step": 840
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.267781376838684,
      "learning_rate": 1.3748633079274253e-05,
      "loss": 1.5615,
      "step": 850
    },
    {
      "epoch": 0.344,
      "grad_norm": 1.856318473815918,
      "learning_rate": 1.2035142713338366e-05,
      "loss": 1.5791,
      "step": 860
    },
    {
      "epoch": 0.348,
      "grad_norm": 1.0773038864135742,
      "learning_rate": 1.042882397605871e-05,
      "loss": 1.4158,
      "step": 870
    },
    {
      "epoch": 0.352,
      "grad_norm": 2.0161309242248535,
      "learning_rate": 8.931633919382298e-06,
      "loss": 1.634,
      "step": 880
    },
    {
      "epoch": 0.356,
      "grad_norm": 1.142063856124878,
      "learning_rate": 7.545396638768698e-06,
      "loss": 1.6887,
      "step": 890
    },
    {
      "epoch": 0.36,
      "grad_norm": 5.741213321685791,
      "learning_rate": 6.2718010508108545e-06,
      "loss": 1.3551,
      "step": 900
    },
    {
      "epoch": 0.364,
      "grad_norm": 0.6307624578475952,
      "learning_rate": 5.1123988355503475e-06,
      "loss": 1.3055,
      "step": 910
    },
    {
      "epoch": 0.368,
      "grad_norm": 7.621210098266602,
      "learning_rate": 4.068602545994249e-06,
      "loss": 1.6785,
      "step": 920
    },
    {
      "epoch": 0.372,
      "grad_norm": 2.7876596450805664,
      "learning_rate": 3.1416838871368924e-06,
      "loss": 1.6619,
      "step": 930
    },
    {
      "epoch": 0.376,
      "grad_norm": 2.8738741874694824,
      "learning_rate": 2.332772166583208e-06,
      "loss": 1.5021,
      "step": 940
    },
    {
      "epoch": 0.38,
      "grad_norm": 3.352921724319458,
      "learning_rate": 1.6428529186614195e-06,
      "loss": 1.4656,
      "step": 950
    },
    {
      "epoch": 0.384,
      "grad_norm": 5.00803279876709,
      "learning_rate": 1.0727667037011668e-06,
      "loss": 1.4822,
      "step": 960
    },
    {
      "epoch": 0.388,
      "grad_norm": 8.808003425598145,
      "learning_rate": 6.232080839403631e-07,
      "loss": 1.5452,
      "step": 970
    },
    {
      "epoch": 0.392,
      "grad_norm": 0.9811484217643738,
      "learning_rate": 2.947247773079753e-07,
      "loss": 1.5076,
      "step": 980
    },
    {
      "epoch": 0.396,
      "grad_norm": 1.8873074054718018,
      "learning_rate": 8.771699011416168e-08,
      "loss": 1.5459,
      "step": 990
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.8034536838531494,
      "learning_rate": 2.4369294605253166e-09,
      "loss": 1.5164,
      "step": 1000
    }
  ],
  "logging_steps": 10,
  "max_steps": 1000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.101007655639245e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
